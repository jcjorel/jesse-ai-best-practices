<!-- ⚠️ DO NOT EDIT MANUALLY! DOCUMENT AUTOMATICALLY GENERATED! ⚠️ -->
<!-- This file is automatically generated by the JESSE Knowledge Base system. -->
<!-- Manual edits will be overwritten during the next generation cycle. -->
<!-- To modify content, update the source files and regenerate the knowledge base. -->
# Directory Knowledge Base {PROJECT_ROOT}/jesse-framework-mcp/tests/

## Global Summary

#### Functional Intent & Features

This directory provides comprehensive test coverage for the Jesse Framework MCP server ecosystem, validating core functionality across knowledge base indexing, HTTP response formatting, resource endpoints, configuration management, and LLM integration components. The test suite ensures system reliability through integration testing, unit testing, and end-to-end validation of real-world project complexity. Key semantic entities include `HierarchicalIndexer`, `FileAnalysisCache`, `IndexingConfig`, `MockContext`, `XAsyncHttpPath`, `format_http_section`, `get_session_init_context`, `StrandsClaude4Driver`, `OrphanedAnalysisCleanup`, `ChangeDetector`, `KnowledgeBuilder`, `pytest`, `asyncio`, `tempfile`, `pathlib.Path`, `FastMCP` decorator unwrapping, `jesse://project/gitignore-files` resource validation, `.knowledge/project-base/` directory structure testing, and comprehensive boundary marker compliance verification. The testing framework enables developers to validate MCP server functionality, knowledge base operations, HTTP protocol compliance, configuration template systems, and AWS Bedrock integration before deployment.

##### Main Components

The directory contains 16 specialized test files organized by functional domain: session initialization testing (`test_session_init_resource.py`), knowledge resource validation (`test_new_resources.py`), LLM driver integration (`test_strands_driver.py`), configuration system validation (`test_default_knowledge_directory.py`, `test_configuration_template_system.py`), HTTP infrastructure testing (`test_http_formatting.py`, `test_http_core_functionality.py`, `test_http_section_formatting.py`, `test_http_path_integration.py`), knowledge base indexing validation (`test_file_analysis_cache_integration.py`, `test_orphaned_cleanup.py`, `test_comprehensive_change_detection.py`, `test_upfront_cache_structure_preparation.py`), business rule compliance (`test_project_base_indexing_rule.py`), integration testing (`test_project_indexing_integration.py`), project setup validation (`test_project_root.py`), resource endpoint testing (`test_gitignore_resource.py`), and debugging utilities (`test_smart_compliance_debug.py`). Supporting components include `MockContext` classes for isolated testing, `unwrap_fastmcp_function` utilities for direct function access, and comprehensive fixture management for temporary directory creation.

###### Architecture & Design

The testing architecture follows a layered validation approach with unit tests for individual components, integration tests for subsystem interactions, and end-to-end tests for complete workflow validation. The design implements isolation patterns using `tempfile.TemporaryDirectory()` for clean test environments, mock context patterns for FastMCP integration testing, and progressive validation strategies with clear success/failure criteria. Test organization separates concerns by functional domain while maintaining comprehensive coverage through cross-cutting integration tests. The architecture includes specialized testing patterns for async operations, HTTP protocol validation, file system operations, configuration management, and real-world project complexity simulation.

####### Implementation Approach

The implementation uses `pytest` framework with class-based organization, async/await patterns for MCP server compatibility, and comprehensive fixture management for test isolation. Testing strategies include direct function testing through FastMCP decorator unwrapping, realistic file system simulation with proper cleanup, timestamp-based validation for change detection, and comprehensive error scenario coverage. The approach implements progressive test execution with detailed logging, emoji-based status indicators for visual feedback, and comprehensive result analysis including statistics tracking and debug artifact preservation. Configuration testing uses hierarchical validation patterns, while integration testing employs conservative settings for stability and comprehensive monitoring for error detection.

######## External Dependencies & Integration Points

**→ Inbound:**
- `jesse_framework_mcp.knowledge_bases.indexing.hierarchical_indexer:HierarchicalIndexer` - core indexing system validation across multiple test files
- `jesse_framework_mcp.knowledge_bases.indexing.file_analysis_cache:FileAnalysisCache` - caching functionality testing and integration validation
- `jesse_framework_mcp.resources.session_init:get_session_init_context` - MCP session initialization resource testing
- `jesse_framework_mcp.helpers.async_http_formatter:format_http_section` - HTTP response formatting validation
- `jesse_framework_mcp.llm.strands_agent_driver:StrandsClaude4Driver` - AWS Bedrock Claude 4 integration testing
- `jesse_framework_mcp.knowledge_bases.models.indexing_config:IndexingConfig` - configuration system validation
- `pytest` (external library) - primary testing framework with fixture management
- `asyncio` (external library) - async execution framework for MCP compatibility
- `tempfile` (external library) - isolated test environment creation
- `pathlib.Path` (external library) - cross-platform path manipulation

**← Outbound:**
- CI/CD pipeline systems consuming test execution results for deployment validation
- Development workflows using test results for functionality verification
- MCP server deployment processes requiring test validation before production
- Debug artifact generation in `/tmp/` directories for troubleshooting analysis

**⚡ System role and ecosystem integration:**
- **System Role**: Critical validation infrastructure ensuring Jesse Framework MCP server reliability across all functional domains before production deployment
- **Ecosystem Position**: Core testing foundation validating the complete MCP server ecosystem from individual components through full integration workflows
- **Integration Pattern**: Executed by developers during development, CI/CD systems for automated validation, and deployment processes for system verification, ensuring comprehensive coverage of MCP protocol compliance, knowledge base operations, HTTP infrastructure, and LLM integration

######### Edge Cases & Error Handling

The test suite validates comprehensive error scenarios including missing project root detection, FastMCP decorator unwrapping failures, HTTP boundary marker compliance violations, knowledge base corruption scenarios, configuration template validation errors, and AWS credential availability issues. Error handling includes graceful degradation when external dependencies are unavailable, comprehensive exception capture with traceback preservation, and detailed diagnostic output for troubleshooting. The tests specifically handle file system permission errors, concurrent operation race conditions, timestamp tolerance validation, orphaned file cleanup edge cases, and integration testing with partial failure tolerance. Mock context implementations provide error simulation capabilities while maintaining test isolation from external systems.

########## Internal Implementation Details

Internal mechanisms include comprehensive fixture management using `pytest.fixture` with `tempfile.TemporaryDirectory()` context managers, emoji-based status reporting for visual test feedback, and detailed timing measurement for performance validation. The test suite implements realistic project structure simulation with nested directories and multiple file types, timestamp manipulation through `time.sleep()` calls for change detection testing, and comprehensive message capture through mock context classes. Configuration testing uses hierarchical object construction with specific parameter validation, while HTTP testing employs byte-perfect content-length calculation and UTF-8 encoding validation. Integration testing includes debug artifact preservation, comprehensive statistics tracking, and multi-criteria success evaluation with configurable thresholds.

########### Usage Examples

Essential test execution patterns demonstrate comprehensive validation workflows for the Jesse Framework MCP server. These examples provide developers with standard approaches for running test suites and validating system functionality.

```python
# Run complete test suite for all components
pytest tests/

# Execute specific functional domain tests
pytest tests/test_session_init_resource.py
pytest tests/test_http_formatting.py
pytest tests/test_project_indexing_integration.py
```

Integration testing patterns enable real-world project validation with comprehensive monitoring and debug capabilities. These approaches support both automated testing and manual troubleshooting workflows.

```python
# Execute comprehensive integration test on actual project
python tests/test_project_indexing_integration.py

# Run with debug output for troubleshooting
python tests/test_project_root.py --dump
```

Mock context implementation provides standardized testing infrastructure for isolated MCP resource validation. This pattern enables comprehensive testing without external system dependencies while maintaining compatibility with MCP server interfaces.

```python
# Standard mock context pattern used across test files
class MockContext:
    def __init__(self):
        self.messages = []
    
    async def info(self, message: str):
        self.messages.append(f"INFO: {message}")
        print(f"ℹ️  {message}")
    
    async def error(self, message: str):
        self.messages.append(f"ERROR: {message}")
        print(f"❌ {message}")
```

## Subdirectory Knowledge Integration

*No subdirectories processed*

## File Knowledge Integration

### {PROJECT_ROOT}/jesse-framework-mcp/tests/test_comprehensive_change_detection.py

*Last Updated: 2025-07-05T18:23:26Z*

#### Functional Intent & Features

This test script validates comprehensive change detection enhancements for the Jesse Framework MCP system, specifically testing enhanced constituent dependency checking for directory knowledge files. The script provides comprehensive validation of `FileAnalysisCache` staleness detection, `ChangeDetector` functionality, and hierarchical dependency propagation mechanisms. Key semantic entities include `FileAnalysisCache`, `ChangeDetector`, `IndexingConfig`, `DirectoryContext`, `FileContext`, `ProcessingStatus`, `MockContext`, `tempfile`, `asyncio`, `pathlib.Path`, `datetime`, and `timedelta`. The testing framework validates timestamp-based staleness detection, cached analysis propagation, subdirectory knowledge file dependencies, and performance optimization through smart change detection algorithms.

##### Main Components

The script contains five primary test functions: `test_file_analysis_cache_staleness_checking()` validates comprehensive staleness checking methods, `test_detailed_staleness_info()` tests detailed staleness information gathering, `test_change_detector_enhancements()` validates enhanced `ChangeDetector` functionality, `test_realistic_change_scenarios()` tests real-world development scenarios, and `test_performance_optimization()` measures performance benefits. Supporting components include `MockContext` class for testing context simulation, `create_directory_context()` helper function for test data creation, and `run_all_tests()` orchestration function for comprehensive test execution.

###### Architecture & Design

The testing architecture follows a hierarchical validation pattern with isolated test environments using `tempfile.TemporaryDirectory()` for each test scenario. The design implements layered processing validation where source file changes do not directly trigger knowledge file rebuilds, ensuring proper separation of concerns. Each test creates realistic project structures with multiple directories, files, and knowledge bases to validate constituent dependency relationships. The `MockContext` class provides async logging simulation for testing framework integration without external dependencies.

####### Implementation Approach

The implementation uses timestamp-based staleness detection with configurable tolerance (`timestamp_tolerance_seconds=0.05`) for precise change detection testing. Tests create realistic file hierarchies, modify timestamps through `time.sleep()` calls, and validate staleness propagation through cached analyses and subdirectory knowledge files. The approach validates that source file modifications trigger cached analysis updates, which then propagate to knowledge file rebuilds through hierarchical dependency chains. Performance testing measures detection times across moderate-sized project structures to validate optimization benefits.

######## External Dependencies & Integration Points

**→ Inbound:**
- `jesse_framework_mcp.knowledge_bases.indexing.file_analysis_cache:FileAnalysisCache` - core caching functionality testing
- `jesse_framework_mcp.knowledge_bases.indexing.change_detector:ChangeDetector` - change detection validation
- `jesse_framework_mcp.knowledge_bases.models.indexing_config:IndexingConfig` - configuration model testing
- `jesse_framework_mcp.knowledge_bases.models.knowledge_context:DirectoryContext` - context model validation
- `tempfile` (standard library) - isolated test environment creation
- `asyncio` (standard library) - async test execution framework
- `pathlib.Path` (standard library) - file system path manipulation

**← Outbound:**
- Test execution results consumed by CI/CD validation systems
- Performance metrics output for optimization tracking
- Validation reports for constituent dependency checking verification

**⚡ System role and ecosystem integration:**
- **System Role**: Critical validation component ensuring constituent dependency checking works correctly across the Jesse Framework MCP knowledge base system
- **Ecosystem Position**: Core testing infrastructure validating the foundation of change detection and caching mechanisms
- **Integration Pattern**: Executed by developers and CI systems to validate knowledge base indexing reliability before deployment

######### Edge Cases & Error Handling

The tests validate missing knowledge file scenarios (should be stale), up-to-date knowledge file detection (should not be stale), source file modification impact (should not directly trigger rebuilds due to layered processing), cached analysis newer than knowledge files (should trigger rebuilds), and subdirectory knowledge files newer than parent directories (should trigger parent rebuilds). Error handling includes assertion failures with descriptive messages, exception catching with traceback printing, and comprehensive test result reporting with pass/fail statistics.

########## Internal Implementation Details

Internal mechanisms include `timestamp_tolerance_seconds=0.05` for precise timing control, `time.sleep(0.1)` calls to ensure proper timestamp ordering, temporary directory cleanup through context managers, and realistic project structure creation with multiple file types. The `MockContext` class captures logging messages for validation, while helper functions like `create_directory_context()` generate proper test data structures. Performance measurement uses `time.time()` for execution timing and calculates performance ratios between different scenarios.

########### Code Usage Examples

Essential test execution pattern for validating change detection:

```python
# Create test environment with proper configuration
with tempfile.TemporaryDirectory() as temp_dir:
    temp_path = Path(temp_dir)
    knowledge_dir = temp_path / ".knowledge"
    source_root = temp_path / "project"
    
    # Configure with small tolerance for testing
    output_config = OutputConfig(knowledge_output_directory=knowledge_dir)
    change_detection = ChangeDetectionConfig(timestamp_tolerance_seconds=0.05)
    config = IndexingConfig(
        handler_type="project-base",
        description="Test configuration for change detection",
        output_config=output_config,
        change_detection=change_detection
    )
```

Staleness checking validation pattern:

```python
# Test staleness detection with file contexts
cache = FileAnalysisCache(config)
file_contexts = [
    FileContext(
        file_path=file1,
        file_size=file1.stat().st_size,
        last_modified=datetime.fromtimestamp(file1.stat().st_mtime)
    )
]

is_stale, reason = cache.is_knowledge_file_stale(
    source_root / "src", source_root, file_contexts
)
assert is_stale == True, "Should be stale when knowledge file missing"
```

Comprehensive change detection testing:

```python
# Validate comprehensive directory change detection
detector = ChangeDetector(config)
directory_context = DirectoryContext(
    directory_path=source_root / "app",
    file_contexts=file_contexts
)

change_info = await detector.check_comprehensive_directory_change(
    directory_context, source_root, ctx
)
assert change_info is not None, "Should detect change when knowledge file missing"
```

### {PROJECT_ROOT}/jesse-framework-mcp/tests/test_configuration_template_system.py

*Last Updated: 2025-07-05T18:23:26Z*

#### Functional Intent & Features

This test suite validates the Configuration Template System for the Jesse Framework MCP knowledge base indexing system, providing comprehensive testing of centralized defaults, JSON configuration auto-generation, and Pydantic validation mechanisms. The test suite ensures proper integration between configuration templates and the `IndexingConfig` system through hierarchical validation patterns. Key semantic entities include `get_default_config`, `get_supported_handler_types`, `validate_handler_type`, `IndexingConfigManager`, `IndexingConfigModel`, `HandlerType`, `PROJECT_BASE_DEFAULT_CONFIG`, `GIT_CLONES_DEFAULT_CONFIG`, `PDF_KNOWLEDGE_DEFAULT_CONFIG`, `pytest`, `tempfile`, `pathlib.Path`, and `unittest.mock.patch`. The testing framework validates handler type support (`project-base`, `git-clones`, `pdf-knowledge`), hierarchical configuration structures, auto-generation of missing configuration files, and Pydantic model validation with specific exclusion patterns for different handler types.

##### Main Components

The test suite contains four primary test classes: `TestDefaultConfigurations` validates centralized default configurations for all handler types, `TestPydanticValidation` tests Pydantic model validation with hierarchical configuration structures, `TestConfigurationManager` validates the `IndexingConfigManager` functionality including auto-generation and caching, and `TestIndexingConfigIntegration` tests integration between the configuration system and `IndexingConfig` class. Additional components include `TestHierarchicalExclusions` for testing exclusion system validation, fixture methods like `temp_knowledge_dir()` for isolated testing environments, and comprehensive validation methods for handler-specific configuration parameters and hierarchical content filtering rules.

###### Architecture & Design

The testing architecture follows a class-based organization pattern with each test class focusing on a specific component of the configuration template system. The design uses `pytest` fixtures for temporary directory management and isolated test environments, ensuring no cross-test contamination. Each test class validates different aspects of the hierarchical configuration system: default configuration templates, Pydantic validation rules, configuration manager operations, and integration patterns. The architecture includes comprehensive validation of handler-specific configurations with different file processing parameters, content filtering rules, and LLM configuration settings for each supported handler type.

####### Implementation Approach

The implementation uses parametric testing patterns to validate multiple handler types (`project-base`, `git-clones`, `pdf-knowledge`) with different configuration parameters and validation rules. Tests validate hierarchical configuration structures by checking nested dictionary values for file processing, content filtering, and LLM configuration sections. The approach includes immutability testing through deep copy validation, caching behavior verification through instance comparison, and error handling validation using `pytest.raises()` context managers. Configuration auto-generation testing uses temporary directories and JSON file validation to ensure proper file creation and content structure.

######## External Dependencies & Integration Points

**→ Inbound:**
- `jesse_framework_mcp.knowledge_bases.indexing.defaults:get_default_config` - centralized default configuration retrieval
- `jesse_framework_mcp.knowledge_bases.indexing.config_manager:IndexingConfigManager` - configuration management and auto-generation
- `jesse_framework_mcp.knowledge_bases.models.indexing_config:IndexingConfig` - core configuration model integration
- `pytest` (external library) - testing framework and fixture management
- `tempfile` (standard library) - isolated test environment creation
- `unittest.mock.patch` (standard library) - mocking for project root detection testing

**← Outbound:**
- Test execution results consumed by CI/CD validation systems
- Configuration template validation reports for deployment verification
- Pydantic model validation metrics for configuration reliability monitoring

**⚡ System role and ecosystem integration:**
- **System Role**: Critical validation component ensuring configuration template system reliability and proper integration with Jesse Framework MCP knowledge base indexing workflow
- **Ecosystem Position**: Core testing infrastructure validating the foundation of configuration management, auto-generation, and hierarchical validation patterns
- **Integration Pattern**: Executed by developers and CI systems to validate configuration template system before deployment, ensuring proper handler type support and configuration file generation

######### Edge Cases & Error Handling

The tests validate unsupported handler type scenarios (should raise `ValueError` with specific error messages), invalid JSON configuration files (should handle parsing errors gracefully), missing project root detection (should raise appropriate errors), and invalid Pydantic model validation (should provide descriptive validation errors). Error handling includes comprehensive validation of configuration immutability through deep copy testing, cache clearing behavior verification, and invalid configuration parameter handling. The tests specifically validate that `project-base` handlers require `project_base_exclusions` while other handlers do not, ensuring proper validation rules for different handler types.

########## Internal Implementation Details

Internal mechanisms include temporary directory fixture management using `pytest.fixture` with `tempfile.TemporaryDirectory()` context managers, configuration file path generation using handler-specific naming patterns (`{handler_type}.indexing-config.json`), and hierarchical configuration validation through nested dictionary access patterns. The testing framework includes comprehensive parameter validation for file processing settings (max_file_size, batch_size, max_concurrent_operations), content filtering exclusions (excluded_extensions, excluded_directories, project_base_exclusions), and LLM configuration parameters (temperature, max_tokens, llm_model). Cache behavior testing uses instance identity comparison to validate proper caching and cache clearing functionality.

########### Code Usage Examples

Essential default configuration validation pattern for handler-specific settings:

```python
# This pattern demonstrates validation of hierarchical default configurations for different handler types
# Each handler type has specific file processing, content filtering, and LLM configuration parameters
config = get_default_config("project-base")

assert config["handler_type"] == "project-base"
assert config["file_processing"]["max_file_size"] == 2 * 1024 * 1024  # 2MB
assert config["file_processing"]["batch_size"] == 7
assert config["content_filtering"]["project_base_exclusions"] is not None
assert ".knowledge" in config["content_filtering"]["project_base_exclusions"]
```

Configuration manager auto-generation testing pattern:

```python
# This pattern validates automatic generation of missing configuration files with proper JSON structure
# The manager creates configuration files on-demand when they don't exist
manager = IndexingConfigManager(temp_knowledge_dir)
config_file = temp_knowledge_dir / "project-base.indexing-config.json"

# Config file shouldn't exist initially
assert not config_file.exists()

# Load config should auto-generate the file
config = manager.load_config("project-base")

# File should now exist with valid JSON content
assert config_file.exists()
with open(config_file, 'r') as f:
    json_config = json.load(f)
assert json_config["handler_type"] == "project-base"
```

Pydantic validation testing for hierarchical configuration structures:

```python
# This pattern validates Pydantic model validation with hierarchical configuration data
# The validation ensures proper structure and handler-specific requirements
config_data = get_default_config("project-base")

# Should validate without errors for valid configuration
config_model = IndexingConfigModel(**config_data)

assert config_model.handler_type == HandlerType.PROJECT_BASE
assert config_model.file_processing.max_file_size == 2 * 1024 * 1024
assert ".knowledge" in config_model.content_filtering.project_base_exclusions
```

### {PROJECT_ROOT}/jesse-framework-mcp/tests/test_default_knowledge_directory.py

*Last Updated: 2025-07-05T18:23:26Z*

#### Functional Intent & Features

This test script validates the default behavior of `IndexingConfig` to automatically set `knowledge_output_directory` to `{PROJECT_ROOT}/.knowledge/` when not explicitly specified, ensuring proper knowledge base storage location configuration within the Jesse Framework MCP ecosystem. It provides comprehensive testing capabilities for default directory assignment, explicit path override functionality, serialization behavior validation, and project root detection integration. The suite enables developers to verify that knowledge indexing operations will correctly default to the standardized `.knowledge/` directory structure. Key semantic entities include `IndexingConfig`, `OutputConfig`, `get_project_root`, `knowledge_output_directory`, `to_dict`, `pathlib.Path`, project root detection, and `.knowledge/` directory convention. The implementation leverages path manipulation and configuration serialization to ensure consistent knowledge storage behavior across different deployment scenarios.

##### Main Components

The test suite contains two primary test functions: `test_default_knowledge_directory()` performs three validation scenarios including default behavior verification, explicit specification override testing, and serialization correctness validation, while `test_project_root_integration()` validates the underlying project root detection mechanism. Supporting components include comprehensive console output formatting with emoji indicators for test status, assertion-based validation with descriptive error messages, and main execution orchestration with success tracking and exit code management. The test structure implements sequential validation with early failure detection and detailed diagnostic output for troubleshooting configuration issues.

###### Architecture & Design

The test architecture follows a sequential validation pattern with three distinct test phases: default behavior validation, explicit override verification, and serialization integrity checking. The design implements graceful degradation when project root detection fails, allowing tests to continue with appropriate fallback behavior validation. Error handling uses assertion-based validation with descriptive failure messages and conditional test execution based on environment capabilities. The architecture separates concerns between configuration behavior testing and underlying utility function validation, enabling independent verification of each component while maintaining integration testing coverage.

####### Implementation Approach

Test execution uses direct function calls with boolean return tracking and comprehensive console output for immediate feedback. Default behavior testing creates `IndexingConfig()` instances without parameters and compares the resulting `knowledge_output_directory` against expected `PROJECT_ROOT/.knowledge/` paths. Override testing instantiates `OutputConfig` with custom paths and verifies that `IndexingConfig(output_config=output_config)` respects explicit specifications. Serialization testing calls `to_dict()` method and validates that the nested dictionary structure contains correct string representations of path objects. Project root integration uses `get_project_root()` directly to verify the underlying path detection mechanism.

######## External Dependencies & Integration Points

**→ Inbound:**
- `jesse_framework_mcp.knowledge_bases.models.indexing_config:IndexingConfig` - core configuration class being tested
- `jesse_framework_mcp.knowledge_bases.models.indexing_config:OutputConfig` - nested configuration for explicit path specification
- `jesse_framework_mcp.helpers.path_utils:get_project_root` - project root detection utility function
- `pathlib.Path` (stdlib) - path manipulation and comparison operations
- `sys` (stdlib) - path modification and exit code management

**← Outbound:**
- Test execution reports for CI/CD pipeline validation
- Configuration behavior verification for knowledge indexing system
- Default directory validation for Jesse Framework MCP deployment
- Integration testing results for knowledge base storage configuration

**⚡ System role and ecosystem integration:**
- **System Role**: Critical validation component ensuring knowledge base storage defaults work correctly before production deployment of indexing operations
- **Ecosystem Position**: Development and testing infrastructure supporting the Jesse Framework MCP knowledge indexing subsystem's default configuration behavior
- **Integration Pattern**: Executed by developers during configuration changes, CI/CD pipelines for regression testing, and deployment validation for knowledge storage setup

######### Edge Cases & Error Handling

The suite handles project root detection failure through conditional test execution with warning messages and fallback behavior validation. When `get_project_root()` returns `None`, tests skip directory comparison but verify that `knowledge_output_directory` also returns `None` as expected fallback behavior. Configuration validation failures trigger assertion errors with descriptive messages indicating which specific test scenario failed. Serialization edge cases are handled by checking for nested dictionary key existence before attempting string comparison. The test framework provides detailed diagnostic output showing expected versus actual values for troubleshooting configuration mismatches.

########## Internal Implementation Details

Path comparison uses direct equality checking between `Path` objects rather than string comparison to ensure platform-independent validation. Test result tracking uses boolean variables with conditional logic for success determination and appropriate exit code setting. Console output formatting employs emoji indicators (`✅`, `❌`, `⚠️`, `🎉`, `💥`) for immediate visual feedback on test status. The serialization test accesses nested dictionary values using `.get()` method with empty dictionary defaults to prevent KeyError exceptions. Project root path construction uses the `/` operator for `Path` objects to ensure proper path joining across different operating systems.

########### Code Usage Examples

**Basic test execution demonstrates the complete validation suite:**
```python
# Run the complete test suite to verify default knowledge directory behavior
python test_default_knowledge_directory.py
```

**Default configuration testing shows automatic directory assignment:**
```python
# Test that IndexingConfig automatically sets knowledge_output_directory to PROJECT_ROOT/.knowledge/
config = IndexingConfig()
expected_knowledge_dir = get_project_root() / '.knowledge'
assert config.knowledge_output_directory == expected_knowledge_dir
```

**Explicit override testing validates custom path specification:**
```python
# Test that explicit specification overrides the default behavior
custom_path = Path("/tmp/custom_knowledge")
output_config = OutputConfig(knowledge_output_directory=custom_path)
config2 = IndexingConfig(output_config=output_config)
assert config2.knowledge_output_directory == custom_path
```

**Serialization validation ensures configuration persistence works correctly:**
```python
# Test that configuration serializes correctly with proper path string conversion
config_dict = config.to_dict()
knowledge_dir_str = config_dict.get('output_config', {}).get('knowledge_output_directory')
expected_str = str(get_project_root() / '.knowledge')
assert knowledge_dir_str == expected_str
```

### {PROJECT_ROOT}/jesse-framework-mcp/tests/test_file_analysis_cache_integration.py

*Last Updated: 2025-07-05T18:23:26Z*

#### Functional Intent & Features

This file provides comprehensive integration testing for the `FileAnalysisCache` system within the Jesse Framework MCP knowledge building pipeline. It validates cache-first processing workflows, metadata handling, timestamp-based freshness detection, and performance optimization through cached analysis retrieval. The test suite ensures `FileAnalysisCache` correctly integrates with `KnowledgeBuilder`, `IndexingConfig`, `FileContext`, and `StrandsClaude4Driver` components while maintaining proper cache invalidation based on file modification timestamps. Key semantic entities include `FileAnalysisCache`, `KnowledgeBuilder`, `MockContext`, `IndexingConfig`, `OutputConfig`, `ChangeDetectionConfig`, `FileContext`, `ProcessingStatus`, `METADATA_START`, `METADATA_END`, `get_cached_analysis()`, `cache_analysis()`, `get_cache_path()`, `build_file_knowledge()`, `timestamp_tolerance_seconds`, and `cache_stats()` enabling comprehensive validation of the caching subsystem's integration points and performance characteristics.

##### Main Components

Contains four primary test functions: `test_cache_basic_functionality()` for storage/retrieval validation, `test_cache_freshness_checking()` for timestamp-based invalidation, `test_cache_integration_with_knowledge_builder()` for end-to-end workflow testing with mock LLM responses, and `test_cache_performance_simulation()` for multi-file cache hit rate analysis. Includes `MockContext` class simulating FastMCP logging interface and `MockKnowledgeBuilder` class extending `KnowledgeBuilder` with deterministic mock responses. The `run_all_cache_tests()` orchestrator executes all test scenarios and provides comprehensive result reporting with pass/fail statistics.

###### Architecture & Design

Implements isolated test environments using `tempfile.TemporaryDirectory()` for each test scenario, ensuring clean state between tests. Uses dependency injection pattern with mock objects (`MockContext`, `MockKnowledgeBuilder`) to eliminate external API dependencies while preserving integration behavior. Follows arrange-act-assert testing pattern with explicit validation checkpoints and detailed error reporting. Test architecture separates concerns between cache mechanics testing, freshness validation, integration workflow testing, and performance simulation through distinct test functions.

####### Implementation Approach

Employs realistic file system simulation with proper directory structures (`src/`, `components/`, `project/`) and authentic file content (Python scripts, TypeScript React components). Uses `asyncio.sleep()` for timestamp manipulation in freshness testing and implements cache hit/miss detection through return value analysis. Mock LLM responses provide deterministic test outcomes while preserving actual cache integration pathways. Performance testing simulates batch processing scenarios with multiple files to validate cache efficiency at scale.

######## External Dependencies & Integration Points

**→ Inbound:**
- `jesse_framework_mcp.knowledge_bases.indexing.knowledge_builder:KnowledgeBuilder` - core knowledge building functionality
- `jesse_framework_mcp.knowledge_bases.indexing.file_analysis_cache:FileAnalysisCache` - primary cache implementation under test
- `jesse_framework_mcp.knowledge_bases.models.indexing_config:IndexingConfig` - configuration management
- `jesse_framework_mcp.knowledge_bases.models.knowledge_context:FileContext` - file processing context
- `jesse_framework_mcp.llm.strands_agent_driver:StrandsClaude4Driver` - LLM integration (mocked)
- `tempfile` (external library) - temporary directory management
- `asyncio` (external library) - asynchronous test execution

**← Outbound:**
- `sys.exit()` - process termination with success/failure codes
- Console output via `print()` - test progress and result reporting
- File system operations through `Path.write_text()` and `Path.read_text()`

**⚡ System role and ecosystem integration:**
- **System Role**: Critical validation component ensuring `FileAnalysisCache` integration reliability within Jesse Framework MCP knowledge building pipeline
- **Ecosystem Position**: Core testing infrastructure validating caching subsystem performance and correctness
- **Integration Pattern**: Executed by developers and CI/CD systems to validate cache implementation before deployment, ensuring knowledge building performance optimization works correctly

######### Edge Cases & Error Handling

Validates cache behavior when source files are modified after caching through timestamp comparison with configurable `timestamp_tolerance_seconds`. Tests cache miss scenarios when cache files don't exist or are stale, ensuring proper fallback to LLM processing. Handles metadata corruption scenarios by validating `METADATA_START` and `METADATA_END` delimiter presence in cache files. Includes whitespace tolerance in content comparison (up to 5 character differences) to handle minor formatting variations between cache storage and retrieval operations.

########## Internal Implementation Details

Cache files are stored with `.analysis.md` extension in knowledge directory structure mirroring source hierarchy. Metadata delimiters (`METADATA_START`, `METADATA_END`) wrap file timestamps and processing information while being stripped from retrieved content. Mock LLM responses are deterministic strings containing realistic analysis content for consistent test validation. Test execution uses temporary directories with automatic cleanup and provides detailed progress logging with emoji indicators for visual test status tracking.

########### Code Usage Examples

**Basic cache functionality validation:**
```python
cache = FileAnalysisCache(config)
test_analysis = "## Test Analysis\n\nThis is a test Python file."
await cache.cache_analysis(test_file, test_analysis, source_root)
retrieved_analysis = await cache.get_cached_analysis(test_file, source_root)
assert retrieved_analysis == test_analysis
```

**Cache freshness testing with file modification:**
```python
# Cache original content
await cache.cache_analysis(test_file, original_analysis, source_root)
# Modify file after caching
await asyncio.sleep(2)
test_file.write_text("# Modified content")
# Verify cache invalidation
stale_retrieval = await cache.get_cached_analysis(test_file, source_root)
assert stale_retrieval is None
```

**Integration testing with KnowledgeBuilder:**
```python
file_context = FileContext(
    file_path=test_file,
    file_size=test_file.stat().st_size,
    last_modified=datetime.fromtimestamp(test_file.stat().st_mtime)
)
result = await builder.build_file_knowledge(file_context, ctx, source_root)
assert result.processing_status == ProcessingStatus.COMPLETED
```

### {PROJECT_ROOT}/jesse-framework-mcp/tests/test_gitignore_resource.py

*Last Updated: 2025-07-05T18:23:26Z*

#### Functional Intent & Features

Test script for validating JESSE Framework MCP server gitignore files resource functionality through direct function testing and HTTP response validation. Provides comprehensive testing of `jesse://project/gitignore-files` resource endpoint with boundary marker verification, writable content validation, and multi-directory gitignore file detection. Features mock context implementation for isolated testing, `FastMCP` decorator unwrapping for direct function access, and detailed response structure analysis. Key semantic entities include `test_gitignore_resource()` function, `MockContext` class, `unwrap_fastmcp_function()` utility, `project_resources.get_project_gitignore_files` resource function, `--JESSE_FRAMEWORK_BOUNDARY_2025--` boundary markers, `X-ASYNC-Content-Writable: true` headers, `X-ASYNC-Content-Section: gitignore-file` section types, `asyncio.run()` execution pattern, and `sys.path.insert()` import configuration. Technical implementation focuses on FastMCP resource testing pattern ensuring boundary marker compliance and HTTP formatting validation.

##### Main Components

- `test_gitignore_resource()` async function implementing comprehensive gitignore resource validation testing
- `MockContext` class providing test context with `info()` and `error()` message logging methods
- `main()` async function handling test execution orchestration and working directory configuration
- `unwrap_fastmcp_function()` utility integration for direct FastMCP decorated function testing
- Response validation logic checking boundary markers, writable headers, and content sections
- Directory presence verification for "Project Root Directory", "Coding Assistant Artifacts", "Knowledge Management System", "Project-Specific Rules"
- Exit code handling with success/failure reporting and detailed test result output

###### Architecture & Design

Implements isolated testing architecture using mock context pattern to avoid external MCP server dependencies. Design separates test execution from validation logic through dedicated verification functions. Uses FastMCP decorator unwrapping strategy enabling direct function testing without MCP protocol overhead. Architecture implements comprehensive response analysis validating HTTP boundary markers, content headers, and section types. Test structure follows async/await patterns matching MCP resource function signatures. Design includes working directory management ensuring tests run from correct project context. Implements detailed logging and verification reporting for debugging and validation transparency.

####### Implementation Approach

Uses `sys.path.insert()` for dynamic import path configuration enabling test module imports. Implements `MockContext` class with async methods matching MCP context interface for isolated testing. Uses `unwrap_fastmcp_function()` utility to extract underlying function from FastMCP decorator for direct invocation. Implements string-based response analysis using `count()` method for boundary marker and header validation. Uses `os.chdir()` for working directory management ensuring tests execute from project root context. Implements comprehensive verification logic checking specific directory sections and content types. Uses `asyncio.run()` for async test execution with proper event loop management.

######## External Dependencies & Integration Points

**→ Inbound:**
- `utils:unwrap_fastmcp_function` - FastMCP decorator unwrapping utility for direct function testing
- `jesse_framework_mcp.resources.project_resources:get_project_gitignore_files` - Target resource function under test
- `asyncio` (external library) - Async execution framework for MCP resource testing
- `pathlib.Path` (external library) - Cross-platform path manipulation for directory management
- `sys` (external library) - Python path configuration for module imports
- `os` (external library) - Working directory management for test context

**← Outbound:**
- `test_execution_reports/` - Test results consumed by CI/CD validation systems
- `development_workflows/` - Manual test execution for gitignore resource validation
- `mcp_server_validation/` - Integration testing for JESSE Framework MCP server functionality

**⚡ System role and ecosystem integration:**
- **System Role**: Critical validation component for JESSE Framework MCP server gitignore resource endpoint ensuring proper HTTP formatting and content delivery
- **Ecosystem Position**: Core testing infrastructure validating MCP resource protocol compliance and boundary marker functionality
- **Integration Pattern**: Executed by developers for resource validation, CI/CD systems for automated testing, and MCP server integration verification workflows

######### Edge Cases & Error Handling

Handles FastMCP decorator unwrapping failures through exception catching and error reporting. Tests missing gitignore file scenarios through error section counting and validation. Manages working directory changes with proper context switching for test isolation. Handles async function execution errors with comprehensive exception catching and detailed error messages. Tests boundary marker absence or malformation through count-based validation. Validates writable header presence ensuring content modification capabilities are properly indicated. Handles missing directory sections through presence verification and detailed reporting of absent components.

########## Internal Implementation Details

Uses `MockContext` class with `messages` list for capturing info and error messages during testing. Implements `sys.path.insert(0, str(Path(__file__).parent))` for relative import configuration. Uses `os.chdir(Path(__file__).parent.parent)` for project root directory context establishment. Implements string counting validation with `result.count("--JESSE_FRAMEWORK_BOUNDARY_2025--")` for boundary marker verification. Uses `exit(0)` and `exit(1)` for process termination with appropriate success/failure codes. Implements detailed console output with emoji indicators for visual test progress tracking. Uses `len(ctx.messages)` for context message counting and test completion reporting.

########### Code Usage Examples

Essential patterns for MCP resource testing and FastMCP function validation. These examples demonstrate comprehensive testing approaches for gitignore resource functionality and HTTP response validation.

```python
# Mock context implementation for isolated MCP resource testing
class MockContext:
    def __init__(self):
        self.messages = []
    
    async def info(self, message: str):
        self.messages.append(f"INFO: {message}")
        print(f"📝 {message}")
    
    async def error(self, message: str):
        self.messages.append(f"ERROR: {message}")
        print(f"❌ {message}")
```

FastMCP decorator unwrapping enables direct function testing without MCP protocol overhead. This approach allows comprehensive validation of resource function behavior and response formatting.

```python
# FastMCP function unwrapping for direct testing access
print("🔧 Unwrapping FastMCP decorated function...")
unwrapped_function = unwrap_fastmcp_function(project_resources.get_project_gitignore_files)
print(f"✅ Successfully unwrapped function: {unwrapped_function.__name__}")

result = await unwrapped_function(ctx)
```

HTTP response validation ensures proper boundary marker formatting and content section identification. This pattern validates MCP resource protocol compliance and content structure.

```python
# Comprehensive HTTP response validation for MCP resource testing
boundary_count = result.count("--JESSE_FRAMEWORK_BOUNDARY_2025--")
print(f"📌 Found {boundary_count} HTTP boundary markers")

writable_count = result.count("X-ASYNC-Content-Writable: true")
print(f"✏️  Found {writable_count} writable content sections")

gitignore_sections = result.count("X-ASYNC-Content-Section: gitignore-file")
error_sections = result.count("X-ASYNC-Content-Section: gitignore-error")
print(f"📄 Found {gitignore_sections} gitignore file sections")
print(f"🚨 Found {error_sections} error sections")
```

Working directory management ensures tests execute from proper project context for accurate resource validation. This approach handles path dependencies and file system access requirements.

```python
# Working directory configuration for proper test context
os.chdir(Path(__file__).parent.parent)
print(f"📂 Working directory: {os.getcwd()}")

success = await test_gitignore_resource()

if success:
    print("\n🎉 All tests passed!")
    exit(0)
else:
    print("\n💔 Tests failed!")
    exit(1)
```

### {PROJECT_ROOT}/jesse-framework-mcp/tests/test_http_core_functionality.py

*Last Updated: 2025-07-05T18:23:26Z*

#### Functional Intent & Features

This file provides comprehensive test coverage for core HTTP functionality within the JESSE Framework MCP server, validating HTTP status code constants, error handling mechanisms, and content criticality classification. The file ensures proper HTTP response generation through testing of `XAsyncHttpStatus` class constants (200, 240, 241, 403, 404, 500), `XAsyncHttpErrorHandler` exception-to-status mapping, and `XAsyncContentCriticality` validation with case-insensitive normalization. Key semantic entities include `XAsyncHttpStatus` for status code management, `XAsyncHttpErrorHandler` for automatic error detection from Python exceptions, `XAsyncContentCriticality` for content priority validation, and `pytest` framework for comprehensive test execution. The testing architecture validates HTTP infrastructure reliability through status code verification, template-based error content generation, and robust input validation.

##### Main Components

The file contains three primary test classes: `TestHttpStatus` validates `XAsyncHttpStatus` class constants and `get_default_message()` method functionality, `TestHttpErrorHandler` tests `XAsyncHttpErrorHandler` error content generation and exception mapping capabilities, and `TestContentCriticality` validates `XAsyncContentCriticality` enum validation with case normalization. Each test class focuses on specific HTTP infrastructure components, providing comprehensive coverage of status code handling, error response generation, and content classification validation with both positive and negative test scenarios.

###### Architecture & Design

The test architecture follows pytest class-based organization with clear separation of HTTP functionality concerns. `TestHttpStatus` validates the foundation layer of HTTP status code constants and message mapping, while `TestHttpErrorHandler` tests the error handling layer that maps Python exceptions to appropriate HTTP responses. `TestContentCriticality` focuses on content classification validation with case-insensitive input handling. The design emphasizes defensive programming validation, template-based error content generation, and extensible HTTP status code support for future additions.

####### Implementation Approach

Tests utilize direct constant validation for `XAsyncHttpStatus` class attributes, ensuring each status code matches expected HTTP standard values. Error handling tests create actual Python exceptions (`FileNotFoundError`, `PermissionError`, `ValueError`) to validate automatic exception-to-status mapping through `detect_error_from_exception()` method. Content criticality testing employs case variation strategies (uppercase, lowercase, mixed case) to validate normalization behavior. The implementation strategy emphasizes comprehensive edge case coverage, template-based error message validation, and robust input validation with descriptive error messages.

######## External Dependencies & Integration Points

**→ Inbound:**
- `jesse_framework_mcp.helpers.async_http_formatter:XAsyncContentCriticality` - content priority classification with validation
- `jesse_framework_mcp.helpers.async_http_formatter:XAsyncHttpStatus` - HTTP status code constants and message mapping
- `jesse_framework_mcp.helpers.async_http_formatter:XAsyncHttpErrorHandler` - exception-to-HTTP-status mapping functionality
- `pytest` (external library) - testing framework for comprehensive HTTP functionality validation

**← Outbound:**
- `test_http_formatting.py` - originally contained these tests before file split for organization
- `CI/CD pipeline/` - automated validation of HTTP infrastructure reliability
- `development workflow/` - ensures HTTP response generation consistency across JESSE Framework

**⚡ System role and ecosystem integration:**
- **System Role**: Critical validation component ensuring JESSE Framework MCP server HTTP infrastructure operates correctly with proper status codes and error handling
- **Ecosystem Position**: Core testing infrastructure validating fundamental HTTP response generation and error handling mechanisms
- **Integration Pattern**: Executed by developers during development and CI/CD systems for continuous validation of HTTP functionality reliability

######### Edge Cases & Error Handling

Error handling validation includes testing unknown status codes with `get_default_message()` returning "Unknown Status" for graceful degradation. Exception mapping tests validate `FileNotFoundError` maps to 404 status, `PermissionError` maps to 403 status, and generic exceptions map to 500 status with detailed error content. Content criticality validation tests invalid inputs raise `ValueError` with descriptive messages specifying valid options. Template-based error content generation handles missing parameters gracefully, and case-insensitive validation ensures robust input handling across various text formats.

########## Internal Implementation Details

The test implementation directly accesses class constants for validation, ensuring `XAsyncHttpStatus.OK == 200` and similar assertions for all supported status codes. Error handler testing creates specific exception instances and validates the three-tuple return format `(status_code, status_message, error_content)` from `detect_error_from_exception()`. Content criticality testing uses `pytest.raises()` context manager for exception validation with specific error message content verification. Template validation ensures error content generation uses proper string formatting with location and detail parameter substitution.

########### Code Usage Examples

Basic HTTP status code validation demonstrates how to verify status constants and retrieve default messages. This pattern ensures HTTP infrastructure operates with correct status codes and provides graceful handling of unknown codes.

```python
# Validate status code constants and retrieve default messages
assert XAsyncHttpStatus.OK == 200
assert XAsyncHttpStatus.get_default_message(404) == "Not Found"
assert XAsyncHttpStatus.get_default_message(999) == "Unknown Status"
```

Exception-to-HTTP-status mapping provides automatic error detection from Python exceptions for consistent HTTP response generation. This approach eliminates manual status code assignment and ensures proper error handling across the framework.

```python
# Automatic error detection from Python exceptions
exc = FileNotFoundError("File not found")
status_code, status_message, error_content = XAsyncHttpErrorHandler.detect_error_from_exception(
    exc, "file://missing.md"
)
# Returns: (404, "Not Found", "Resource not found: file://missing.md")
```

Content criticality validation demonstrates case-insensitive input handling with normalization to uppercase format. This pattern ensures consistent content classification regardless of input case variations.

```python
# Case-insensitive criticality validation
assert XAsyncContentCriticality.validate("critical") == "CRITICAL"
assert XAsyncContentCriticality.validate("InFormAtional") == "INFORMATIONAL"

# Invalid input handling
with pytest.raises(ValueError) as exc_info:
    XAsyncContentCriticality.validate("invalid")
```

### {PROJECT_ROOT}/jesse-framework-mcp/tests/test_http_formatting.py

*Last Updated: 2025-07-05T18:23:26Z*

#### Functional Intent & Features

Test suite organization and backward compatibility reference file for JESSE Framework MCP server HTTP formatting infrastructure. Provides centralized import aggregation from three specialized test modules (`test_http_core_functionality.py`, `test_http_section_formatting.py`, `test_http_path_integration.py`) maintaining existing test runner compatibility after large test file refactoring. Features graceful import error handling with placeholder classes and comprehensive re-export functionality. Key semantic entities include `TestHttpStatus`, `TestHttpErrorHandler`, `TestContentCriticality`, `TestHTTPSectionFormatting`, `TestMultiSectionResponse`, `TestHttpPath`, `TestPortablePathResolution`, `__all__` export list, `ImportError` exception handling, `warnings.warn()` for diagnostic messaging, and relative import patterns using dot notation. Technical implementation focuses on backward compatibility preservation through import aggregation and fallback mechanisms.

##### Main Components

- Import aggregation from `test_http_core_functionality` module containing `TestHttpStatus`, `TestHttpErrorHandler`, `TestContentCriticality` classes
- Import aggregation from `test_http_section_formatting` module containing `TestHttpStatusLines`, `TestHTTPSectionFormatting`, `TestMultiSectionResponse`, `TestExtractHttpSections`, `TestFormatHttpResponse`, `TestIntegrationWithConstants` classes
- Import aggregation from `test_http_path_integration` module containing `TestPortablePathResolution`, `TestHttpPath`, `TestPathContentHandling`, `TestPerformanceAndEdgeCases` classes
- `__all__` export list defining public API for backward compatibility
- Exception handling block with `ImportError` catching and `warnings.warn()` messaging
- Placeholder class definitions providing empty test classes when imports fail

###### Architecture & Design

Implements aggregator pattern consolidating distributed test modules into single import point. Design uses try-catch import strategy with graceful degradation to placeholder classes preventing import failures. Architecture separates concerns through specialized test modules while maintaining unified access interface. Uses relative import syntax with dot notation for module-relative imports. Implements comprehensive re-export strategy through `__all__` list ensuring all test classes remain discoverable. Error handling architecture provides diagnostic warnings without breaking test discovery mechanisms. Placeholder class design maintains class structure with docstring references to actual implementation locations.

####### Implementation Approach

Uses Python relative import mechanism with `from .module_name import` syntax for sibling module access. Implements comprehensive exception handling wrapping all imports in single try-catch block. Uses `warnings.warn()` with `ImportWarning` category for non-fatal diagnostic messaging. Implements placeholder class generation with descriptive docstrings indicating actual test locations. Uses `__all__` list for explicit public API definition enabling controlled re-export. Implements graceful fallback strategy creating empty classes with pass statements when imports fail. Documentation string provides comprehensive module organization explanation and usage guidance for developers.

######## External Dependencies & Integration Points

**→ Inbound:**
- `tests/test_http_core_functionality.py:TestHttpStatus` - HTTP status code and utility test classes
- `tests/test_http_core_functionality.py:TestHttpErrorHandler` - Error handling and exception mapping tests
- `tests/test_http_section_formatting.py:TestHTTPSectionFormatting` - HTTP section formatting functionality tests
- `tests/test_http_path_integration.py:TestHttpPath` - HttpPath dual-path functionality tests
- `warnings` (external library) - Warning system for import failure diagnostics
- `ImportError` (external library) - Exception handling for failed module imports

**← Outbound:**
- `pytest` test discovery systems - Discovers and executes aggregated test classes
- `test_runners/` - CI/CD systems consuming unified test interface
- `coverage_tools/` - Code coverage analysis tools accessing test classes
- `ide_integrations/` - Development environment test discovery mechanisms

**⚡ System role and ecosystem integration:**
- **System Role**: Central test aggregation point maintaining backward compatibility after test suite refactoring while enabling modular test organization
- **Ecosystem Position**: Core testing infrastructure component bridging legacy test runners with new modular test architecture
- **Integration Pattern**: Used by pytest discovery, CI/CD pipelines, and development tools requiring unified test class access without modification to existing test execution workflows

######### Edge Cases & Error Handling

Handles `ImportError` exceptions when specialized test modules are missing or corrupted through comprehensive try-catch wrapping. Provides diagnostic `warnings.warn()` messaging with specific module names and helpful resolution guidance. Creates placeholder classes with descriptive docstrings preventing test discovery failures when imports fail. Handles partial import failures where some modules succeed and others fail through individual class imports. Manages circular import scenarios through relative import syntax avoiding absolute path dependencies. Provides graceful degradation maintaining test runner compatibility even with missing test modules. Handles module path resolution issues in different execution contexts through dot notation relative imports.

########## Internal Implementation Details

Uses `try-except ImportError` block wrapping all relative imports with specific error message construction including failed module names. Implements `warnings.warn()` with `ImportWarning` category and detailed diagnostic message including resolution steps. Creates placeholder classes using `class ClassName: pass` pattern with docstring references to actual implementation files. Uses `__all__` list containing 14 test class names organized by functional categories (core, formatting, integration). Implements relative import syntax `from .module_name import` requiring package context execution. Placeholder classes maintain identical names to imported classes ensuring test discovery compatibility. Documentation string uses triple-quote format with detailed module organization explanation and developer guidance.

########### Code Usage Examples

Essential patterns for test aggregation and backward compatibility maintenance. These examples demonstrate import aggregation strategies and error handling mechanisms for maintaining test suite organization.

```python
# Comprehensive import aggregation with error handling for test module organization
try:
    from .test_http_core_functionality import (
        TestHttpStatus,
        TestHttpErrorHandler,
        TestContentCriticality
    )
    from .test_http_section_formatting import (
        TestHttpStatusLines,
        TestHTTPSectionFormatting
    )
except ImportError as e:
    warnings.warn(f"Could not import split test modules: {e}")
```

Backward compatibility export list configuration ensures test discovery systems continue working without modification. This pattern maintains API stability while enabling internal reorganization.

```python
# Backward compatibility export list ensuring test discovery works unchanged
__all__ = [
    'TestHttpStatus',
    'TestHttpErrorHandler', 
    'TestContentCriticality',
    'TestHttpStatusLines',
    'TestHTTPSectionFormatting'
]
```

Placeholder class creation prevents import failures while providing clear guidance to developers. This fallback mechanism maintains test runner compatibility even when specialized modules are missing.

```python
# Placeholder class creation preventing import failures while providing guidance
class TestHttpStatus:
    """Placeholder - actual tests in test_http_core_functionality.py"""
    pass

class TestHttpErrorHandler:
    """Placeholder - actual tests in test_http_core_functionality.py"""
    pass
```

Diagnostic warning system provides specific resolution guidance for missing test modules. This approach helps developers quickly identify and resolve import issues during development.

```python
# Diagnostic warning with specific resolution guidance for missing modules
warnings.warn(
    f"Could not import split test modules: {e}. "
    "Ensure test_http_core_functionality.py, test_http_section_formatting.py, "
    "and test_http_path_integration.py are present in the tests/ directory.",
    ImportWarning
)
```

### {PROJECT_ROOT}/jesse-framework-mcp/tests/test_http_path_integration.py

*Last Updated: 2025-07-05T18:23:26Z*

#### Functional Intent & Features

This file provides comprehensive test coverage for `XAsyncHttpPath` class dual-path functionality and portable path resolution within the JESSE Framework MCP server. The file validates cross-platform path variable substitution (`{PROJECT_ROOT}`, `{HOME}`, `{CLINE_RULES}`, `{CLINE_WORKFLOWS}`), HTTP formatting integration with location headers, and automatic file content loading with `Last-Modified` header generation. Key semantic entities include `XAsyncHttpPath` class for dual-path storage, `resolve_portable_path` function for variable substitution, `format_http_section` for HTTP response formatting, `tempfile` module for filesystem testing, and `pytest` framework for comprehensive test execution. The testing architecture ensures portable path resolution maintains original variable preservation while enabling filesystem operations on resolved paths.

##### Main Components

The file contains four primary test classes: `TestPortablePathResolution` validates `resolve_portable_path` function behavior with all supported environment variables, `TestHttpPath` tests `XAsyncHttpPath` class construction and dual-path functionality, `TestPathContentHandling` validates file content reading with automatic `Last-Modified` header integration, and `TestPerformanceAndEdgeCases` ensures performance with large content and special character handling. Each test class focuses on specific aspects of path resolution and HTTP integration, providing comprehensive coverage of portable path functionality, filesystem operations, and HTTP response generation.

###### Architecture & Design

The test architecture follows pytest conventions with class-based organization separating concerns by functional area. `TestPortablePathResolution` validates the foundation layer of path variable substitution, while `TestHttpPath` tests the `XAsyncHttpPath` wrapper class that inherits from `Path` while preserving original portable paths. `TestPathContentHandling` focuses on integration between file system operations and HTTP formatting, particularly automatic `Last-Modified` header generation from file modification times. The design emphasizes cross-platform compatibility testing, error condition validation, and integration testing between path resolution and HTTP response formatting components.

####### Implementation Approach

Tests utilize temporary file creation with `tempfile.NamedTemporaryFile` for realistic filesystem testing scenarios, ensuring proper cleanup with try-finally blocks. Path resolution testing validates variable substitution using `Path.cwd()` and `Path.home()` for environment-independent assertions. The `XAsyncHttpPath` testing strategy verifies dual-path functionality by comparing `get_original_path()` preservation against `str()` resolution results. Integration testing combines `XAsyncHttpPath` objects with `format_http_section` to validate automatic file content reading and `Last-Modified` header generation. Error handling tests cover file not found scenarios, empty content validation, and invalid type checking with specific exception assertions.

######## External Dependencies & Integration Points

**→ Inbound:**
- `jesse_framework_mcp.helpers.async_http_formatter:format_http_section` - HTTP response formatting with automatic content loading
- `jesse_framework_mcp.helpers.async_http_formatter:XAsyncHttpPath` - dual-path storage class for portable path handling
- `jesse_framework_mcp.helpers.path_utils:resolve_portable_path` - environment variable substitution in paths
- `jesse_framework_mcp.constants:CONTENT_TYPES` - HTTP content type constants for validation
- `pytest` (external library) - testing framework for comprehensive test execution
- `tempfile` (external library) - temporary file creation for filesystem testing
- `pathlib.Path` (external library) - cross-platform path operations and validation

**← Outbound:**
- `test_http_formatting.py` - originally contained these tests before file split for organization
- `CI/CD pipeline` - automated test execution validating portable path functionality
- `development workflow` - validates JESSE Framework MCP server path handling reliability

**⚡ System role and ecosystem integration:**
- **System Role**: Critical validation component ensuring JESSE Framework MCP server handles portable paths correctly across different deployment environments
- **Ecosystem Position**: Core testing infrastructure validating fundamental path resolution and HTTP integration functionality
- **Integration Pattern**: Executed by developers during development and CI/CD systems for continuous validation of cross-platform path handling

######### Edge Cases & Error Handling

Error handling tests validate `TypeError` exceptions for invalid content types passed to `format_http_section`, ensuring clear error messages specify expected types (`str` or `XAsyncHttpPath`). File system error scenarios include automatic 404 HTTP response generation when `XAsyncHttpPath` content files don't exist, and `ValueError` exceptions for empty file content validation. Unicode content testing ensures proper UTF-8 encoding with accurate byte-length calculation for international characters and emoji. Cross-platform path resolution testing handles environment variable availability and path separator differences. Performance testing validates large content handling (10KB+ content blocks) without memory issues or formatting corruption.

########## Internal Implementation Details

The test implementation uses `tempfile.NamedTemporaryFile` with explicit encoding='utf-8' for consistent cross-platform file handling. Cleanup operations utilize `unlink(missing_ok=True)` for safe temporary file removal. Path resolution validation compares resolved paths against `Path.cwd()` and `Path.home()` results for environment independence. HTTP header validation uses string parsing and regular expression matching for RFC 7231 timestamp format verification. The `XAsyncHttpPath` testing strategy accesses both `_resolved_path` internal attribute for cleanup and public methods for functionality validation. Performance tests generate large content using string multiplication for consistent memory usage patterns.

########### Code Usage Examples

Basic `XAsyncHttpPath` construction and dual-path access:
```python
# Create HttpPath with portable variable
http_path = XAsyncHttpPath("file://{PROJECT_ROOT}/.knowledge/test.md")

# Access original portable path for headers
original = http_path.get_original_path()  # "file://{PROJECT_ROOT}/.knowledge/test.md"

# Access resolved path for filesystem operations
resolved = str(http_path)  # "/actual/project/path/.knowledge/test.md"
```

Integration with HTTP formatting for automatic content loading:
```python
# HttpPath object automatically reads file content and adds Last-Modified header
result = format_http_section(
    content=XAsyncHttpPath("{HOME}/Cline/Rules/JESSE_HINTS.md"),
    content_type="text/markdown",
    criticality="CRITICAL",
    description="Framework Rules",
    section_type="framework-rule",
    location="file://{HOME}/Cline/Rules/JESSE_HINTS.md"
)
```

Portable path resolution testing pattern:
```python
# Test environment variable substitution
location = "file://{PROJECT_ROOT}/.knowledge/test.md"
resolved = resolve_portable_path(location)

# Validate variable replacement
assert "{PROJECT_ROOT}" not in resolved
assert str(Path.cwd()) in resolved
```

### {PROJECT_ROOT}/jesse-framework-mcp/tests/test_http_section_formatting.py

*Last Updated: 2025-07-05T18:23:26Z*

#### Functional Intent & Features

This file provides comprehensive test coverage for HTTP section formatting and multi-section response functionality within the JESSE Framework MCP server, validating HTTP/1.1-like status line generation, content-length accuracy, and multi-part response assembly. The file ensures proper HTTP response generation through testing of `format_http_section` with automatic error detection, `format_multi_section_response` for combining sections, `extract_http_sections_from_multi_response` for content extraction, and `format_http_response` for simple API responses. Key semantic entities include `format_http_section` for individual section formatting, `XAsyncHttpPath` for file-based content loading, `XAsyncContentCriticality` for content priority validation, `HTTP_BOUNDARY_MARKER` for section separation, `CONTENT_TYPES` for media type validation, and `pytest` framework for comprehensive test execution. The testing architecture validates HTTP infrastructure through status code verification (200, 240, 241, 403, 404, 500), byte-perfect content-length calculation, and multi-section protocol definition integration.

##### Main Components

The file contains six primary test classes: `TestHttpStatusLines` validates HTTP/1.1 status line functionality with automatic error detection and manual overrides, `TestHTTPSectionFormatting` tests comprehensive HTTP section formatting with parameter validation, `TestMultiSectionResponse` validates combining multiple sections with protocol definitions, `TestExtractHttpSections` tests extraction of HTTP sections from multi-responses, `TestFormatHttpResponse` validates simple HTTP response formatting for API integration, and `TestIntegrationWithConstants` ensures proper integration with JESSE Framework constants. Each test class focuses on specific HTTP formatting aspects, providing comprehensive coverage of status handling, content formatting, section combination, and framework integration.

###### Architecture & Design

The test architecture follows pytest class-based organization with clear separation of HTTP formatting concerns across different functional layers. `TestHttpStatusLines` validates the foundation layer of HTTP status code handling with automatic error detection from filesystem exceptions, while `TestHTTPSectionFormatting` tests the core formatting layer with comprehensive parameter validation. `TestMultiSectionResponse` focuses on the aggregation layer that combines individual sections with protocol definitions, and `TestExtractHttpSections` tests the parsing layer for content extraction. The design emphasizes comprehensive edge case coverage, realistic filesystem testing with temporary files, and integration validation with framework constants for real-world compatibility.

####### Implementation Approach

Tests utilize temporary file creation with `tempfile.NamedTemporaryFile` for realistic filesystem error scenarios, ensuring proper cleanup with try-finally blocks and permission restoration. HTTP status line testing validates automatic error detection by creating actual Python exceptions (`FileNotFoundError`, `PermissionError`) and verifying appropriate status code mapping. Content-length accuracy testing employs UTF-8 encoding validation with international characters to ensure byte-perfect calculations. Multi-section response testing combines pre-formatted sections and validates protocol definition inclusion with XML-wrapped preambule functionality. The implementation strategy emphasizes comprehensive parameter validation, realistic error condition simulation, and integration testing with actual framework constants.

######## External Dependencies & Integration Points

**→ Inbound:**
- `jesse_framework_mcp.helpers.async_http_formatter:format_http_section` - core HTTP section formatting with status line generation
- `jesse_framework_mcp.helpers.async_http_formatter:format_multi_section_response` - multi-section response assembly with protocol definitions
- `jesse_framework_mcp.helpers.async_http_formatter:XAsyncHttpPath` - file-based content loading with automatic error detection
- `jesse_framework_mcp.helpers.async_http_formatter:extract_http_sections_from_multi_response` - content extraction from multi-responses
- `jesse_framework_mcp.constants:HTTP_BOUNDARY_MARKER` - section separation marker for multi-part responses
- `jesse_framework_mcp.constants:CONTENT_TYPES` - media type constants for integration validation
- `pytest` (external library) - testing framework for comprehensive HTTP functionality validation
- `tempfile` (external library) - temporary file creation for filesystem error testing
- `stat` (external library) - file permission manipulation for access control testing

**← Outbound:**
- `test_http_formatting.py` - originally contained these tests before file split for organization
- `CI/CD pipeline/` - automated validation of HTTP section formatting reliability
- `development workflow/` - ensures HTTP response generation consistency across JESSE Framework MCP server

**⚡ System role and ecosystem integration:**
- **System Role**: Critical validation component ensuring JESSE Framework MCP server HTTP section formatting operates correctly with proper status codes, content-length accuracy, and multi-section response assembly
- **Ecosystem Position**: Core testing infrastructure validating fundamental HTTP response generation, error handling, and multi-part content formatting mechanisms
- **Integration Pattern**: Executed by developers during development and CI/CD systems for continuous validation of HTTP formatting functionality across different content types and error scenarios

######### Edge Cases & Error Handling

Error handling validation includes automatic status code detection with `FileNotFoundError` mapping to 404, `PermissionError` mapping to 403, and generic exceptions mapping to 500 status codes. Content validation tests empty content raises `ValueError`, empty header names/values raise descriptive errors, and whitespace-only parameters trigger appropriate validation failures. Multi-section response testing validates empty section arrays raise errors, whitespace-only sections are rejected, and protocol definition inclusion works correctly. UTF-8 content-length calculation testing ensures byte-perfect accuracy with international characters, emoji, and special characters. Permission testing handles system-dependent behavior with `pytest.skip()` for unreliable permission enforcement scenarios.

########## Internal Implementation Details

The test implementation uses `tempfile.NamedTemporaryFile` with explicit `encoding='utf-8'` and `delete=False` for controlled file lifecycle management. Permission testing employs `stat.S_IWRITE` for write-only permissions and `chmod()` for access control simulation. Content-length validation compares `len(content.encode('utf-8'))` against header values for byte-perfect accuracy verification. Multi-section response testing validates XML tag wrapping for preambule content and protocol definition positioning. Status line testing accesses internal `_resolved_path` attribute for cleanup operations and validates three-tuple return format from error detection methods. Header ordering validation uses line-by-line parsing to verify Content-Location and Content-Length appear before other headers.

########### Code Usage Examples

Basic HTTP section formatting demonstrates standard parameter usage with automatic 200 OK status generation. This pattern provides the foundation for all HTTP section formatting in the JESSE Framework.

```python
# Basic HTTP section formatting with automatic status detection
result = format_http_section(
    content="# Test Content\nThis is a test.",
    content_type="text/markdown",
    criticality="CRITICAL",
    description="Test Content",
    section_type="framework-rule",
    location="file://{HOME}/test.md"
)
# Generates: X-ASYNC-HTTP/1.1 200 OK with proper headers and content
```

Manual status override functionality allows complete control over HTTP status codes and error content generation. This approach enables custom error handling and specialized status scenarios.

```python
# Manual status override with custom error content
result = format_http_section(
    content="Original content",
    content_type="text/plain",
    criticality="CRITICAL",
    description="Custom Error Test",
    section_type="error-section",
    location="service://maintenance/",
    status_code=503,
    status_message="Service Unavailable",
    error_content="Service is temporarily unavailable due to maintenance."
)
# Generates: X-ASYNC-HTTP/1.1 503 Service Unavailable with custom error content
```

Multi-section response assembly combines individual HTTP sections with automatic protocol definition inclusion. This pattern enables complex multi-part responses with proper section separation and documentation.

```python
# Multi-section response with protocol definition and preambule
section1 = format_http_section(content="Content 1", content_type="text/plain", 
                              criticality="CRITICAL", description="Section 1",
                              section_type="framework-rule", location="file://{HOME}/section1.txt")

section2 = format_http_section(content="Content 2", content_type="text/markdown",
                              criticality="INFORMATIONAL", description="Section 2", 
                              section_type="knowledge-base", location="file://{HOME}/section2.md")

result = format_multi_section_response(section1, section2, 
                                     preambule="Important contextual information")
# Generates: Multi-part response with XML-wrapped preambule and protocol definition
```

### {PROJECT_ROOT}/jesse-framework-mcp/tests/test_new_resources.py

*Last Updated: 2025-07-05T18:23:26Z*

#### Functional Intent & Features

This test script validates knowledge resource functionality for the JESSE Framework MCP Server, specifically testing README.md resources in the `.knowledge/` directory structure. The script provides automated validation of knowledge base file existence, content verification, and resource registration processes for MCP server integration. Key semantic entities include `test_git_clones_readme()`, `test_pdf_knowledge_readme()`, `test_resource_registration()` functions, `register_knowledge_resources` import, `asyncio` async execution framework, `pathlib.Path` file system operations, and `.knowledge/git-clones/README.md` and `.knowledge/pdf-knowledge/README.md` file paths. The testing framework enables developers to verify that knowledge base resources are properly accessible through the MCP server with appropriate content validation and graceful handling of missing directories.

##### Main Components

The script contains three primary async test functions: `test_git_clones_readme()` for validating git clones knowledge base README file, `test_pdf_knowledge_readme()` for PDF knowledge directory validation, and `test_resource_registration()` for verifying MCP resource registration. The `main()` function orchestrates sequential test execution with formatted console output. Each test function implements file existence checking, content validation, and expected content pattern matching with emoji-based status reporting for visual test result differentiation.

###### Architecture & Design

The test architecture follows a sequential validation pattern where individual knowledge resources are tested independently before validating the overall registration process. The design implements file system validation using `os.path.exists()` checks combined with content analysis for expected headers and knowledge base references. The script uses graceful degradation for missing directories, treating them as expected conditions for new installations rather than failures. Error isolation ensures that individual test failures do not prevent execution of subsequent tests.

####### Implementation Approach

The testing strategy employs direct file system access using `os.path.exists()` and file reading operations with UTF-8 encoding for content validation. Content verification uses string containment checks for expected headers like "Git Clone Knowledge Bases Index" and knowledge base references like "FastMCP" and "Cline". The implementation includes character counting for content size validation and pattern matching for structural verification. Resource registration testing uses direct function calls to `register_knowledge_resources()` with exception handling for registration failures.

######## External Dependencies & Integration Points

**→ Inbound:**
- `jesse_framework_mcp.resources.knowledge:register_knowledge_resources` - knowledge resource registration function
- `jesse_framework_mcp.main:server` - MCP server instance for integration context
- `fastmcp.Context` (external library) - MCP context interface specification
- `asyncio` (stdlib) - async execution framework
- `pathlib.Path` (stdlib) - file system path manipulation
- `os` (stdlib) - file existence and directory operations
- `.knowledge/git-clones/README.md` - git clones knowledge base index file
- `.knowledge/pdf-knowledge/README.md` - PDF knowledge base index file

**← Outbound:**
- Test execution reports consumed by developers for validation
- Console output with emoji-based status indicators for debugging
- Validation results for CI/CD pipeline integration

**⚡ System role and ecosystem integration:**
- **System Role**: Validation component ensuring knowledge base resources are properly configured and accessible through MCP server endpoints
- **Ecosystem Position**: Supporting test infrastructure for JESSE Framework knowledge management system validation
- **Integration Pattern**: Executed by developers during development and automated testing pipelines to verify knowledge resource availability and content integrity

######### Edge Cases & Error Handling

The script handles multiple edge cases including missing knowledge directories (treated as expected for new installations), missing README files (with appropriate warning messages), and content validation failures when expected headers or references are absent. Exception handling includes comprehensive error catching with string representation of exceptions for debugging. The testing framework differentiates between critical failures (registration errors) and expected conditions (missing PDF knowledge directory) using different emoji indicators and message types.

########## Internal Implementation Details

The test functions implement emoji-based status reporting using Unicode characters (`✅`, `❌`, `⚠️`) for immediate visual feedback on test results. File content validation includes character counting with length reporting and specific string pattern matching for expected content elements. The script uses UTF-8 encoding explicitly for file reading operations to handle international characters in knowledge base content. Resource registration testing validates that the registration process completes without exceptions rather than testing specific registration outcomes.

########### Code Usage Examples

**Basic knowledge resource file validation pattern:**

This code demonstrates file existence checking and content validation for knowledge base resources. It provides a foundation for testing README files in knowledge directories with appropriate error handling.

```python
# Test file existence and content validation for knowledge resources
readme_path = ".knowledge/git-clones/README.md"
if os.path.exists(readme_path):
    with open(readme_path, 'r', encoding='utf-8') as f:
        content = f.read()
    if "Git Clone Knowledge Bases Index" in content:
        print("✅ Git clones README contains expected header")
```

**Resource registration validation for MCP server integration:**

This pattern validates that knowledge resources register successfully with the MCP server. It ensures the registration process completes without exceptions and provides appropriate error reporting.

```python
# Validate that knowledge resources register successfully with MCP server
try:
    register_knowledge_resources()
    print("✅ Knowledge resources registered successfully")
except Exception as e:
    print(f"❌ Resource registration test failed: {str(e)}")
```

**Sequential test execution with formatted output:**

This approach orchestrates comprehensive knowledge resource validation with visual formatting. It provides structured test execution with clear section boundaries for debugging purposes.

```python
# Execute comprehensive knowledge resource validation suite
async def main():
    print("=" * 60)
    print("TESTING NEW WRITABLE RESOURCES")
    await test_git_clones_readme()
    await test_pdf_knowledge_readme()
    await test_resource_registration()
```

### {PROJECT_ROOT}/jesse-framework-mcp/tests/test_orphaned_cleanup.py

*Last Updated: 2025-07-05T18:23:26Z*

#### Functional Intent & Features

This file provides comprehensive test coverage for the `OrphanedAnalysisCleanup` component within the Jesse Framework MCP knowledge building system. It validates orphaned file detection and removal functionality, ensuring proper cleanup of stale analysis files and knowledge files when their corresponding source files no longer exist. The test suite verifies directory structure preservation, leaf-first traversal algorithms, and cleanup statistics reporting through `pytest` framework integration. Key semantic entities include `OrphanedAnalysisCleanup`, `IndexingConfig`, `OutputConfig`, `cleanup_orphaned_files()`, `_collect_directories_leaf_first()`, `temp_directories`, `indexing_config`, `mock_context`, `analysis_files_deleted`, `knowledge_files_deleted`, `directories_deleted`, `total_items_deleted`, `project-base`, `.analysis.md`, and `_kb.md` enabling validation of knowledge base maintenance operations and file system consistency checks.

##### Main Components

Contains `TestOrphanedAnalysisCleanup` test class with six test methods: `test_cleanup_orphaned_analysis_files()` for validating removal of orphaned analysis files, `test_cleanup_orphaned_knowledge_files()` for knowledge file cleanup validation, `test_preserve_directories_with_content()` for content preservation verification, `test_no_cleanup_needed()` for empty structure handling, `test_preserve_empty_directories_with_existing_source()` for source-mirrored directory preservation, and `test_leaf_first_directory_collection()` for traversal algorithm validation. Includes three `pytest` fixtures: `temp_directories()` for temporary file system setup, `indexing_config()` for test configuration creation, and `mock_context()` for FastMCP context mocking.

###### Architecture & Design

Implements isolated test environments using `tempfile.TemporaryDirectory()` with structured directory hierarchies mirroring real knowledge base layouts. Uses `pytest` fixture dependency injection pattern for test setup and teardown management. Employs mock objects (`AsyncMock`) for external dependency isolation while preserving integration behavior. Test architecture separates concerns between orphaned file detection, directory preservation logic, cleanup statistics validation, and traversal algorithm verification through distinct test methods with clear arrange-act-assert patterns.

####### Implementation Approach

Creates realistic file system scenarios with `source_root/` and `knowledge_root/` directory structures containing `.analysis.md` and `_kb.md` files. Uses `Path.write_text()` and `Path.exists()` for file manipulation and validation. Implements cleanup statistics verification through assertion checks on `stats.analysis_files_deleted`, `stats.knowledge_files_deleted`, and `stats.directories_deleted` counters. Validates leaf-first directory traversal by creating nested directory structures and verifying collection order through index comparison of directory names.

######## External Dependencies & Integration Points

**→ Inbound:**
- `jesse_framework_mcp.knowledge_bases.models:IndexingConfig` - configuration model for cleanup operations
- `jesse_framework_mcp.knowledge_bases.indexing.orphaned_cleanup:OrphanedAnalysisCleanup` - primary cleanup component under test
- `jesse_framework_mcp.knowledge_bases.models.indexing_config:OutputConfig` - output directory configuration
- `fastmcp:Context` - FastMCP context interface for logging operations
- `pytest` (external library) - testing framework and fixture management
- `tempfile` (external library) - temporary directory creation for isolated testing
- `unittest.mock:AsyncMock` (external library) - mock object creation for context isolation

**← Outbound:**
- `pytest.main()` - test execution entry point when run as script
- File system operations through `Path.mkdir()`, `Path.write_text()`, and `Path.exists()`
- Console output via `pytest` test result reporting

**⚡ System role and ecosystem integration:**
- **System Role**: Critical validation component ensuring `OrphanedAnalysisCleanup` reliability within Jesse Framework MCP knowledge base maintenance workflows
- **Ecosystem Position**: Core testing infrastructure validating cleanup subsystem correctness and preventing knowledge base corruption
- **Integration Pattern**: Executed by developers and CI/CD systems to validate cleanup implementation before deployment, ensuring knowledge base integrity and preventing orphaned file accumulation

######### Edge Cases & Error Handling

Validates preservation of directories with existing source counterparts even when empty, ensuring source-mirrored directory structures remain intact. Tests cleanup behavior when no orphaned files exist, verifying zero-impact operations on clean knowledge bases. Handles nested directory structures with proper leaf-first traversal to prevent directory deletion order conflicts. Validates content preservation logic by ensuring directories containing analysis files or subdirectories are never removed regardless of source file status.

########## Internal Implementation Details

Test fixtures create temporary directory structures with `source/` and `knowledge/project-base/` hierarchies. Analysis files use `.analysis.md` extension while knowledge files use `_kb.md` suffix for directory-level knowledge. Cleanup statistics are tracked through dedicated counter fields in the cleanup result object. Leaf-first directory collection is validated by creating `level1/level2/level3/` nested structures and verifying traversal order through list index comparisons of directory names.

########### Code Usage Examples

**Basic orphaned analysis file cleanup test setup:**
```python
# Creates test environment with source file and corresponding analysis file, plus orphaned analysis file
source_file = source_root / "existing_file.py"
source_file.write_text("print('hello world')")
valid_analysis = project_base_dir / "existing_file.py.analysis.md"
valid_analysis.write_text("# Analysis of existing_file.py")
orphaned_analysis = project_base_dir / "deleted_file.py.analysis.md"
orphaned_analysis.write_text("# Analysis of deleted_file.py")
```

**Cleanup execution and validation pattern:**
```python
# Executes cleanup operation and validates results through statistics checking
cleanup = OrphanedAnalysisCleanup(indexing_config)
stats = await cleanup.cleanup_orphaned_files(knowledge_root, source_root, mock_context)
assert stats.analysis_files_deleted == 1
assert not orphaned_analysis.exists()
assert valid_analysis.exists()
```

**Leaf-first directory traversal validation:**
```python
# Validates proper directory collection order for safe deletion operations
directories = cleanup._collect_directories_leaf_first(project_base)
directory_names = [d.name for d in directories]
assert directory_names.index("level3") < directory_names.index("level2")
assert directory_names.index("level2") < directory_names.index("level1")
```

### {PROJECT_ROOT}/jesse-framework-mcp/tests/test_project_base_indexing_rule.py

*Last Updated: 2025-07-05T18:23:26Z*

#### Functional Intent & Features

This test script validates the project-base indexing business rule implementation for the Jesse Framework MCP system, specifically testing that knowledge files are stored in `{PROJECT_ROOT}/.knowledge/project-base/` with directory structure mirroring when `handler_type="project-base"`. The script provides comprehensive validation of mandatory project-base subdirectory usage, configuration detection, and fallback behavior mechanisms. Key semantic entities include `KnowledgeBuilder`, `IndexingConfig`, `OutputConfig`, `handler_type`, `project-base`, `git-clones`, `tempfile`, `pathlib.Path`, `_get_knowledge_file_path`, and `.knowledge/project-base/` directory structure. The testing framework validates that all configurations now use the project-base/ subdirectory regardless of handler type, eliminating backward compatibility for consistent knowledge file organization.

##### Main Components

The script contains three primary test functions: `test_project_base_indexing_path_rule()` validates correct directory structure usage with project-base indexing, `test_business_rule_configuration_detection()` tests configuration detection between project-base and git-clones handler types, and `test_mandatory_project_base_subdirectory()` validates that project-base/ subdirectory is mandatory regardless of configuration. Supporting components include temporary directory creation using `tempfile.TemporaryDirectory()`, path validation logic comparing expected vs actual knowledge file paths, and comprehensive test result reporting with pass/fail status indicators.

###### Architecture & Design

The testing architecture follows an isolated environment pattern using `tempfile.TemporaryDirectory()` for each test scenario, ensuring no cross-test contamination. The design validates business rule enforcement by creating realistic project structures with nested directories (`src/components/ui/buttons/`) and verifying knowledge file path generation follows the mandatory project-base/ pattern. Each test creates `KnowledgeBuilder` instances with different `IndexingConfig` settings to validate that all configurations produce identical project-base/ subdirectory paths, confirming the elimination of backward compatibility.

####### Implementation Approach

The implementation uses direct path comparison validation by calling `_get_knowledge_file_path()` method on `KnowledgeBuilder` instances and comparing results against expected paths. Tests validate multi-level directory structure preservation within project-base/, fallback behavior when relative path calculation fails, and flat structure handling when no source_root is provided. The approach includes comprehensive edge case testing with unrelated directory paths and various configuration combinations to ensure consistent project-base/ subdirectory usage across all scenarios.

######## External Dependencies & Integration Points

**→ Inbound:**
- `jesse_framework_mcp.knowledge_bases.indexing.knowledge_builder:KnowledgeBuilder` - core knowledge file path generation testing
- `jesse_framework_mcp.knowledge_bases.models.indexing_config:IndexingConfig` - configuration model validation
- `jesse_framework_mcp.knowledge_bases.models.indexing_config:OutputConfig` - output configuration testing
- `tempfile` (standard library) - isolated test environment creation
- `pathlib.Path` (standard library) - file system path manipulation and validation

**← Outbound:**
- Test execution results consumed by CI/CD validation systems
- Business rule compliance reports for deployment verification
- Configuration validation metrics for system reliability monitoring

**⚡ System role and ecosystem integration:**
- **System Role**: Critical validation component ensuring project-base indexing business rule compliance across the Jesse Framework MCP knowledge base system
- **Ecosystem Position**: Core testing infrastructure validating the foundation of knowledge file organization and directory structure consistency
- **Integration Pattern**: Executed by developers and CI systems to validate business rule enforcement before deployment, ensuring all knowledge files follow mandatory project-base/ subdirectory structure

######### Edge Cases & Error Handling

The tests validate missing source_root scenarios (should use flat structure in project-base/), unrelated directory paths (should use fallback naming in project-base/), multi-level nested directories (should preserve structure within project-base/), and different handler_type configurations (should all use project-base/ subdirectory). Error handling includes assertion failures with descriptive messages for incorrect paths, comprehensive path comparison logging, and detailed test result reporting with specific expected vs actual path information. The tests specifically validate that no backward compatibility exists and all configurations produce consistent project-base/ subdirectory usage.

########## Internal Implementation Details

Internal mechanisms include temporary directory structure creation with nested paths like `src/components/ui/buttons/`, direct method invocation on `KnowledgeBuilder._get_knowledge_file_path()` for path generation testing, and comprehensive path validation comparing expected project-base/ patterns against actual results. The testing framework creates multiple `IndexingConfig` instances with different `handler_type` values to validate consistent behavior, while path comparison logic ensures exact matching of expected `.knowledge/project-base/` subdirectory structures with proper knowledge base file naming conventions.

########### Code Usage Examples

Essential project-base indexing path validation pattern:

```python
# This pattern demonstrates validation of mandatory project-base subdirectory usage regardless of handler type
# All configurations must produce paths within .knowledge/project-base/ directory structure
output_config = OutputConfig(knowledge_output_directory=knowledge_dir)
config_with_project_base = IndexingConfig(
    handler_type="project-base",
    description="Test configuration with project-base indexing",
    output_config=output_config
)

builder = KnowledgeBuilder(config_with_project_base)
knowledge_path = builder._get_knowledge_file_path(test_directory, source_root)
expected_path = knowledge_dir / "project-base" / "src" / "components" / "components_kb.md"
```

Configuration detection and validation testing:

```python
# This pattern validates that different handler types still use project-base subdirectory (no backward compatibility)
# Both project-base and git-clones configurations produce identical path structures
project_base_config = IndexingConfig(handler_type="project-base")
regular_config = IndexingConfig(handler_type="git-clones")

builder_project_base = KnowledgeBuilder(project_base_config)
builder_regular = KnowledgeBuilder(regular_config)

project_base_path = builder_project_base._get_knowledge_file_path(test_directory, source_root)
regular_path = builder_regular._get_knowledge_file_path(test_directory, source_root)

# Both paths should be identical and use project-base/ subdirectory
assert project_base_path == regular_path
```

Multi-level directory structure validation:

```python
# This pattern validates that complex nested directory structures are preserved within project-base subdirectory
# Deep directory hierarchies maintain their structure under the mandatory project-base/ root
deep_directory = source_root / "src" / "components" / "ui" / "buttons"
deep_path = builder._get_knowledge_file_path(deep_directory, source_root)

expected_deep_path = knowledge_dir / "project-base" / "src" / "components" / "ui" / "buttons" / "buttons_kb.md"
assert deep_path == expected_deep_path
```

### {PROJECT_ROOT}/jesse-framework-mcp/tests/test_project_indexing_integration.py

*Last Updated: 2025-07-05T18:23:26Z*

#### Functional Intent & Features

This integration test validates the Knowledge Bases Hierarchical Indexing System by executing real-world indexing operations on the actual Jesse Framework project root, providing comprehensive verification of system functionality with authentic project complexity. The test provides end-to-end validation of hierarchical indexing capabilities, error detection mechanisms, and performance monitoring through real project structures and files. Key semantic entities include `HierarchicalIndexer`, `IndexingConfig`, `IndexingMode`, `ProcessingStatus`, `MockContext`, `FileProcessingConfig`, `ChangeDetectionConfig`, `ErrorHandlingConfig`, `DebugConfig`, `ensure_project_root`, `asyncio`, `tempfile`, `shutil`, `pathlib.Path`, and `datetime`. The testing framework validates real-world project indexing through `FULL_KB_REBUILD` mode with comprehensive message capture, debug artifact generation, and success criteria analysis including file processing rates and error thresholds.

##### Main Components

The test contains two primary functions: `test_real_project_indexing()` executes comprehensive integration testing on the actual project root with real file structures and complexity, and `main()` serves as the test runner providing clear pass/fail determination and result reporting. Supporting components include `MockContext` class for capturing all indexing messages (info, debug, warning, error) with real-time display and categorized storage, project structure analysis logic for counting processable vs excluded files and directories, comprehensive configuration setup using hierarchical config objects, and detailed success criteria evaluation including processing statistics and debug artifact verification.

###### Architecture & Design

The testing architecture follows a single comprehensive integration test pattern targeting the actual Jesse Framework project root for authentic complexity validation. The design uses `MockContext` for complete message capture with categorized storage and real-time display, enabling comprehensive monitoring of indexing operations. The architecture includes hierarchical configuration construction using specific config objects (`FileProcessingConfig`, `ChangeDetectionConfig`, `ErrorHandlingConfig`, `DebugConfig`) with conservative settings for stability. The test creates isolated debug directories for artifact preservation and implements comprehensive success criteria analysis with multiple validation checkpoints.

####### Implementation Approach

The implementation uses dynamic project root detection through `ensure_project_root()` with comprehensive error handling for environment validation. The approach includes pre-indexing project structure analysis to count total vs processable files and identify excluded directories, providing baseline metrics for success evaluation. Configuration uses conservative settings (batch_size=5, max_concurrent_operations=1, continue_on_file_errors=True) to maximize stability during integration testing. The test captures comprehensive timing information, processing statistics, and message categorization for detailed analysis, with success criteria based on completion status, file processing rates, and debug artifact generation.

######## External Dependencies & Integration Points

**→ Inbound:**
- `jesse_framework_mcp.knowledge_bases.indexing.hierarchical_indexer:HierarchicalIndexer` - core indexing system validation
- `jesse_framework_mcp.knowledge_bases.models.indexing_config:IndexingConfig` - configuration model integration
- `jesse_framework_mcp.knowledge_bases.models.knowledge_context:ProcessingStatus` - status tracking validation
- `jesse_framework_mcp.helpers.path_utils:ensure_project_root` - dynamic project root detection
- `asyncio` (standard library) - async execution framework for indexing operations
- `tempfile` (standard library) - debug directory creation and management
- `pathlib.Path` (standard library) - file system path manipulation and analysis

**← Outbound:**
- Integration test results consumed by CI/CD validation systems
- Debug artifacts preserved in `/tmp/jesse_project_indexing_integration_test/` for analysis
- Processing statistics and success metrics for system reliability monitoring

**⚡ System role and ecosystem integration:**
- **System Role**: Critical end-to-end validation ensuring the hierarchical indexing system works correctly with real-world project complexity and file structures
- **Ecosystem Position**: Core integration testing infrastructure validating the complete indexing workflow from project discovery through knowledge base generation
- **Integration Pattern**: Executed by developers and CI systems to validate system reliability before deployment, ensuring real project indexing capabilities work correctly

######### Edge Cases & Error Handling

The test validates project root detection failures (should provide clear error messages and exit gracefully), indexing system initialization errors (should capture setup failures with detailed diagnostics), and individual file processing failures (should continue processing with error tracking). Error handling includes comprehensive exception capture with traceback preservation, message categorization for different error types, and success criteria that allow partial failures while detecting critical system issues. The test specifically handles missing project root scenarios, configuration initialization failures, and indexing execution exceptions with detailed error reporting and debug artifact preservation.

########## Internal Implementation Details

Internal mechanisms include dynamic project structure analysis using `iterdir()` and `rglob()` for comprehensive file counting and processability assessment, debug directory management with automatic cleanup and recreation for isolated test runs, and comprehensive message capture through `MockContext` with separate lists for different message types. The test includes detailed timing measurement from start to completion, processing statistics extraction from indexing results, and success criteria evaluation based on multiple checkpoints including completion status, file processing rates, message counts, and debug artifact generation. Configuration uses hierarchical object construction with specific parameter values optimized for integration testing stability.

########### Code Usage Examples

Essential integration test configuration pattern for real project indexing:

```python
# This pattern demonstrates comprehensive configuration setup for real-world project indexing validation
# Conservative settings ensure stability while providing thorough testing of indexing capabilities
file_processing = FileProcessingConfig(
    max_file_size=2 * 1024 * 1024,  # 2MB limit
    batch_size=5,                    # Moderate batch size for stability
    max_concurrent_operations=1      # Conservative concurrency
)

change_detection = ChangeDetectionConfig(
    indexing_mode=IndexingMode.FULL_KB_REBUILD  # Thorough rebuild for integration testing
)

config = IndexingConfig(
    handler_type="project-base",
    description="Integration test configuration",
    file_processing=file_processing,
    change_detection=change_detection,
    error_handling=error_handling,
    debug_config=debug_config
)
```

Project structure analysis and validation pattern:

```python
# This pattern demonstrates comprehensive project analysis before indexing execution
# Provides baseline metrics for success evaluation and identifies processing scope
total_files = 0
processable_files = 0
excluded_dirs = 0

for item in project_root.iterdir():
    if item.is_dir():
        if config.should_process_directory(item):
            dir_files = list(item.rglob("*"))
            total_in_dir = len([f for f in dir_files if f.is_file()])
            processable_in_dir = len([f for f in dir_files if f.is_file() and config.should_process_file(f)])
            processable_files += processable_in_dir
        else:
            excluded_dirs += 1

print(f"SUMMARY: {processable_files}/{total_files} files processable, {excluded_dirs} directories excluded")
```

Comprehensive success criteria evaluation pattern:

```python
# This pattern demonstrates multi-faceted success evaluation for integration testing
# Combines multiple validation checkpoints to determine overall system functionality
success_criteria = {
    "Indexing completed": result.overall_status == ProcessingStatus.COMPLETED,
    "Files discovered": stats.total_files_discovered > 0,
    "Some files processed": stats.files_processed > 0,
    "Progress messages": len(ctx.info_messages) > 0,
    "No critical failure": len(ctx.error_messages) < stats.total_files_discovered,
    "Debug files generated": len(debug_files) > 0
}

files_success_rate = (stats.files_completed / max(stats.total_files_discovered, 1)) * 100
integration_success = all_criteria_met and files_success_rate > 50
```

### {PROJECT_ROOT}/jesse-framework-mcp/tests/test_project_root.py

*Last Updated: 2025-07-05T18:23:26Z*

#### Functional Intent & Features

This file provides comprehensive testing capabilities for the Jesse Framework MCP server's project root detection and session initialization functionality, validating the core project setup workflow that enables proper MCP resource operation. The test suite validates `get_project_root`, `ensure_project_root`, `get_project_relative_path`, and `validate_project_setup` functions from `jesse_framework_mcp.helpers.path_utils`, along with `get_project_setup_guidance` from `jesse_framework_mcp.helpers.project_setup` and `get_session_init_context` from `jesse_framework_mcp.resources.session_init`. Key semantic entities include `test_project_root_detection` async function, `test_session_init_with_project_root` async function, `TestContext` mock class, `JESSE_PROJECT_ROOT` environment variable detection, `unwrap_fastmcp_function` utility integration, `argparse` command-line interface with `--dump` flag, and comprehensive emoji-based status reporting (✅, ❌, ℹ️, 🧪, 📋, 📊). The testing framework implements both summary and content dump modes for debugging session initialization resource generation.

##### Main Components

The file contains five primary test functions: `test_project_root_detection` validates basic project root discovery through environment variables and Git repository detection, `test_session_init_with_project_root` tests MCP resource session initialization with project context, `main` orchestrates test execution with conditional dump mode support, `parse_arguments` handles command-line argument parsing with `argparse.ArgumentParser`, and the `TestContext` class provides mock MCP context interface with async logging methods (`info`, `error`, `warning`, `debug`, `report_progress`). The test suite implements dual execution modes through the `dump_content` parameter, enabling both comprehensive testing and direct resource content inspection for debugging purposes.

###### Architecture & Design

The architecture follows a modular testing pattern that separates project root detection validation from session initialization testing, enabling independent verification of each component while supporting integrated workflow testing. The design implements a mock context pattern through `TestContext` that simulates the MCP server's logging interface without requiring full server infrastructure, while the dual-mode execution pattern allows switching between comprehensive test reporting and raw resource content dumping. The structure uses progressive test numbering (🧪 Test 1-5) for clear test phase identification and implements conditional output formatting based on execution mode to support both developer debugging and automated testing scenarios.

####### Implementation Approach

The implementation uses async/await patterns throughout to match the MCP server's asynchronous execution model, with `unwrap_fastmcp_function` handling FastMCP framework integration for testing MCP resources directly. The testing strategy employs sequential validation steps with immediate visual feedback through emoji-based indicators, comprehensive environment detection including `JESSE_PROJECT_ROOT` variable and `.git` directory traversal, and detailed result analysis with character counting and content sampling. The approach implements exception handling with `traceback.print_exc()` for debugging, command-line argument processing with help text and examples, and conditional content dumping that outputs complete resource content for integration testing.

######## External Dependencies & Integration Points

**→ Inbound:**
- `jesse_framework_mcp.helpers.path_utils:get_project_root` - core project root detection function
- `jesse_framework_mcp.helpers.path_utils:validate_project_setup` - project validation functionality
- `jesse_framework_mcp.helpers.project_setup:get_project_setup_guidance` - setup guidance generation
- `jesse_framework_mcp.resources.session_init:get_session_init_context` - MCP session initialization resource
- `utils:unwrap_fastmcp_function` - FastMCP function unwrapping utility
- `asyncio` (external library) - Python async event loop management
- `argparse` (external library) - command-line argument parsing
- `pathlib.Path` (external library) - modern path manipulation

**← Outbound:**
- Direct script execution via `python test_project_root.py` - standalone testing tool
- Console output for developer debugging sessions - formatted test results and resource content
- Command-line interface with `--dump` flag - resource content extraction for integration testing

**⚡ System role and ecosystem integration:**
- **System Role**: Serves as the primary validation tool for Jesse Framework MCP server project setup and session initialization, ensuring proper project root detection before MCP resource operation
- **Ecosystem Position**: Critical testing component that validates the foundation layer of the MCP server, particularly the project context establishment that all other MCP resources depend on
- **Integration Pattern**: Used by developers during setup validation, CI/CD pipelines for project verification, and debugging sessions when session initialization fails or returns setup guidance instead of project context

######### Edge Cases & Error Handling

The test suite handles multiple failure scenarios including missing project root when neither `JESSE_PROJECT_ROOT` environment variable nor Git repository detection succeeds, import failures when required helper modules or MCP resources are unavailable, session initialization failures during FastMCP function unwrapping or execution, and context interface mismatches between `TestContext` mock and actual MCP context requirements. The comprehensive exception handling uses `traceback.print_exc()` for detailed error diagnosis, while the conditional testing approach allows graceful handling of setup guidance generation when project root detection fails. The dual-mode execution pattern provides fallback debugging capabilities when normal test execution encounters issues, and the emoji-based status indicators clearly distinguish between different types of failures and warnings.

########## Internal Implementation Details

The `TestContext` class implements a minimal MCP context interface with async methods that print formatted messages using emoji prefixes, with conditional output suppression in dump mode to prevent interference with resource content extraction. The main testing functions use structured print statements with section dividers and progress indicators, implement try-catch blocks around critical operations to prevent test termination, and perform detailed analysis including character counting, content sampling, and section counting for HTTP-formatted responses. The argument parsing uses `argparse.RawDescriptionHelpFormatter` for proper help text formatting with examples, while the path manipulation leverages `pathlib.Path` for cross-platform compatibility and the Git detection implements manual directory traversal using parent directory iteration.

########### Code Usage Examples

**Direct execution for comprehensive project root testing:**
```python
# Run complete test suite with detailed output
python test_project_root.py
```

**Content dump mode for debugging session initialization resource:**
```python
# Extract complete session initialization resource content
python test_project_root.py --dump
```

**Integration pattern for testing MCP resource functions:**
```python
# Example of how the test unwraps and executes MCP resources
from utils import unwrap_fastmcp_function
session_init_func = unwrap_fastmcp_function(get_session_init_context)
result = await session_init_func(ctx)
# Provides direct access to MCP resource output for validation
```

**Mock context implementation for isolated MCP resource testing:**
```python
# TestContext class pattern for simulating MCP server context
class TestContext:
    async def info(self, message):
        print(f"ℹ️  {message}")
    async def error(self, message):
        print(f"❌ {message}")
# Enables testing MCP resources without full server infrastructure
```

### {PROJECT_ROOT}/jesse-framework-mcp/tests/test_session_init_resource.py

*Last Updated: 2025-07-05T18:23:26Z*

#### Functional Intent & Features

This test script validates the `jesse://session/init-context` meta-resource functionality for the JESSE Framework MCP Server, specifically testing comprehensive session initialization for Cline AI assistant integration. The script provides automated validation of multi-section HTTP response formatting, resource aggregation correctness, and individual component isolation testing. Key semantic entities include `get_session_init_context`, `TestContext` class, `unwrap_fastmcp_function` utility, `asyncio` async execution, `fastmcp.Context` integration, and `jesse_framework_mcp.resources` module ecosystem. The testing framework enables developers to verify that all essential project resources (framework rules, project context, WIP tasks, workflows, knowledge, gitignore) are properly aggregated into a single meta-resource endpoint with appropriate HTTP Content-Type boundaries and criticality levels.

##### Main Components

The script contains three primary async functions: `test_session_init_resource()` for comprehensive meta-resource validation, `test_individual_sections()` for isolated component testing, and `main()` for orchestrated test execution. A custom `TestContext` class provides mock context implementation with logging methods (`info`, `error`, `warning`, `debug`, `report_progress`) that simulate the MCP server context interface. The testing logic includes result analysis functionality that counts HTTP sections, verifies key resource sections, and provides detailed output sampling for debugging purposes.

###### Architecture & Design

The test architecture follows an isolation-first testing pattern where individual resource sections are validated before comprehensive integration testing. The design implements a mock context pattern using `TestContext` class to simulate the MCP server environment without requiring full server initialization. The script uses dynamic module importing and function unwrapping to test FastMCP-decorated functions directly, enabling unit-level testing of resource endpoints. Error handling is implemented at multiple levels with detailed traceback reporting and graceful degradation for individual section failures.

####### Implementation Approach

The testing strategy employs async/await patterns throughout with `asyncio.run()` orchestration for proper async context management. Function unwrapping is achieved through the `unwrap_fastmcp_function` utility to bypass FastMCP decorators and enable direct function testing. Result validation uses string analysis techniques including character counting, section boundary detection via "Content-Type:" markers, and pattern matching for expected resource sections. The implementation includes progress reporting simulation and detailed output sampling with truncated display for large responses.

######## External Dependencies & Integration Points

**→ Inbound:**
- `jesse_framework_mcp.main:server` - MCP server instance for testing context
- `jesse_framework_mcp.resources.session_init:get_session_init_context` - primary meta-resource function under test
- `jesse_framework_mcp.resources.framework_rules:get_available_rule_names` - individual framework rules testing
- `jesse_framework_mcp.resources.project_resources:get_project_context_summary` - project context validation
- `jesse_framework_mcp.resources.wip_tasks:get_wip_tasks_inventory` - WIP tasks resource testing
- `utils:unwrap_fastmcp_function` - FastMCP function unwrapping utility
- `fastmcp.Context` (external library) - MCP context interface specification
- `asyncio` (stdlib) - async execution framework
- `pathlib.Path` (stdlib) - file system path manipulation

**← Outbound:**
- Test execution reports consumed by developers for validation
- Console output for debugging and verification purposes
- Validation results for CI/CD pipeline integration

**⚡ System role and ecosystem integration:**
- **System Role**: Critical validation component ensuring MCP server resource endpoints function correctly before deployment
- **Ecosystem Position**: Core testing infrastructure for JESSE Framework MCP server resource validation
- **Integration Pattern**: Executed by developers during development and CI/CD pipelines for automated resource endpoint validation

######### Edge Cases & Error Handling

The script handles multiple error scenarios including missing resource sections, empty meta-resource responses, individual section failures, and FastMCP function unwrapping errors. Exception handling includes full traceback printing for debugging with specific error categorization (test failures vs unexpected errors). The testing framework gracefully handles keyboard interrupts and provides detailed failure analysis when resource sections are missing or malformed. Individual section testing isolates failures to specific resource types, enabling targeted debugging when the comprehensive meta-resource fails.

########## Internal Implementation Details

The `TestContext` class implements emoji-based logging (`ℹ️`, `❌`, `⚠️`, `🐛`, `📊`) for visual test output differentiation. Result analysis includes character counting with comma formatting, HTTP section boundary detection, and key section verification against expected patterns. The script uses dynamic module importing with `__import__` and `getattr` for flexible resource function testing. Progress reporting simulation includes percentage calculation and formatted output for testing the meta-resource's progress reporting capabilities.

########### Code Usage Examples

**Basic test execution for session initialization validation:**
```python
# Execute comprehensive session initialization test
success = await test_session_init_resource()
if success:
    print("Meta-resource validation passed")
```

**Individual resource section testing for debugging:**
```python
# Test specific resource sections in isolation
sections_to_test = [
    ("Framework Rules", "framework_rules", "get_available_rule_names"),
    ("Project Context", "project_resources", "get_project_context_summary")
]
for section_name, module_name, function_name in sections_to_test:
    module = __import__(f'jesse_framework_mcp.resources.{module_name}', fromlist=[function_name])
    test_func = getattr(module, function_name)
    unwrapped_func = unwrap_fastmcp_function(test_func)
    result = await unwrapped_func(ctx)
```

**Custom test context implementation for MCP simulation:**
```python
class TestContext:
    async def info(self, message):
        print(f"ℹ️  {message}")
    
    async def report_progress(self, current, total, message):
        percentage = (current / total) * 100
        print(f"📊 [{percentage:3.0f}%] {message}")
```

### {PROJECT_ROOT}/jesse-framework-mcp/tests/test_smart_compliance_debug.py

*Last Updated: 2025-07-05T18:23:26Z*

#### Functional Intent & Features

This file provides isolated debugging capabilities for the `get_gitignore_compliance_status` function within the Jesse Framework MCP server, specifically testing the smart compliance detection mechanism. The debug test validates that the `get_gitignore_compliance_status` function from `jesse_framework_mcp.resources.gitignore` can be properly imported, unwrapped via `unwrap_fastmcp_function`, and executed to detect gitignore compliance violations. Key semantic entities include `DebugContext` class, `debug_smart_compliance` async function, `get_gitignore_compliance_status` MCP resource function, `unwrap_fastmcp_function` utility, `asyncio` event loop management, and comprehensive error handling with `traceback` analysis. The test implements a structured validation approach using emoji-based status indicators (✅, ❌, ⚠️, 📊) for clear visual feedback during debugging sessions.

##### Main Components

The file contains three primary components: the `DebugContext` class that provides mock logging context with `info` and `error` methods for testing isolation, the `debug_smart_compliance` async function that orchestrates the complete testing workflow, and the main execution block using `asyncio.run` for direct script execution. The `DebugContext` simulates the MCP server context interface required by the compliance function, while `debug_smart_compliance` performs sequential validation steps including function import verification, unwrapping validation, execution testing, and result analysis with detailed output formatting.

###### Architecture & Design

The architecture follows a test isolation pattern that decouples the compliance function from the full MCP server context, enabling focused debugging without server infrastructure dependencies. The design implements a mock context pattern through `DebugContext` to satisfy the function's interface requirements, while the sequential testing approach provides step-by-step validation with clear success/failure indicators. The structure separates concerns between context mocking, function testing, and result analysis, allowing developers to identify specific failure points in the compliance detection pipeline.

####### Implementation Approach

The implementation uses async/await patterns throughout to match the MCP server's asynchronous execution model, with `unwrap_fastmcp_function` handling the FastMCP framework's function decoration layer. The testing strategy employs progressive validation steps with immediate feedback, comprehensive exception handling using `traceback.print_exc()` for detailed error diagnosis, and result analysis including type inspection, length measurement, and content preview. The approach prioritizes developer experience through emoji-based visual indicators and structured output formatting that clearly distinguishes between different test phases and outcomes.

######## External Dependencies & Integration Points

**→ Inbound:**
- `jesse_framework_mcp.resources.gitignore:get_gitignore_compliance_status` - core compliance detection function being tested
- `utils:unwrap_fastmcp_function` - utility for unwrapping FastMCP decorated functions
- `asyncio` (external library) - Python async event loop management
- `traceback` (external library) - Python exception stack trace analysis

**← Outbound:**
- Direct script execution via `python test_smart_compliance_debug.py` - standalone debugging tool
- Console output for developer debugging sessions - formatted test results and error diagnostics

**⚡ System role and ecosystem integration:**
- **System Role**: Serves as an isolated testing harness for the Jesse Framework MCP server's gitignore compliance detection functionality, enabling developers to debug compliance issues without full server startup
- **Ecosystem Position**: Peripheral debugging tool that validates core MCP resource functionality outside the main server execution context
- **Integration Pattern**: Used by developers during debugging sessions to isolate and test the `get_gitignore_compliance_status` function, particularly when troubleshooting compliance detection failures or validating function behavior changes

######### Edge Cases & Error Handling

The debug script handles multiple error scenarios including import failures when `get_gitignore_compliance_status` or `unwrap_fastmcp_function` are unavailable, unwrapping failures if the FastMCP decoration is incompatible, execution failures during compliance function runtime, and context interface mismatches between `DebugContext` and expected MCP context. The comprehensive exception handling uses `traceback.print_exc()` to provide full stack traces for debugging, while the sequential testing approach isolates failure points to specific operations. Result validation includes empty string detection for no compliance issues versus content detection for compliance violations, with type and length analysis for unexpected return formats.

########## Internal Implementation Details

The `DebugContext` class implements a minimal interface with async `info` and `error` methods that print formatted messages, satisfying the compliance function's logging requirements without full MCP context overhead. The main debugging function uses structured print statements with emoji prefixes for visual parsing, implements try-catch around the entire testing sequence to prevent script termination, and performs detailed result analysis including `type()`, `len()`, and `repr()` inspection. The script uses `if __name__ == "__main__"` pattern for direct execution while maintaining importability, and the `asyncio.run()` call handles the async context management for the debugging session.

########### Code Usage Examples

**Direct script execution for debugging compliance detection:**
```python
# Run the debug script directly to test compliance function
python test_smart_compliance_debug.py
```

**Expected output format for successful compliance testing:**
```python
# Console output showing test progression
=== DEBUGGING SMART COMPLIANCE ===
1. Testing function import...
✅ Function imported and unwrapped successfully
2. Testing function execution...
✅ Function executed successfully
📊 Result type: <class 'str'>
📊 Result length: 0 chars
📊 Result preview: ''
✅ No compliance issues - function returned empty string
```

**Integration pattern for testing compliance function in isolation:**
```python
# Example of how the debug script isolates and tests the compliance function
compliance_func = unwrap_fastmcp_function(get_gitignore_compliance_status)
result = await compliance_func(ctx)
# Provides detailed analysis without full MCP server context
```

### {PROJECT_ROOT}/jesse-framework-mcp/tests/test_strands_driver.py

*Last Updated: 2025-07-05T18:23:26Z*

#### Functional Intent & Features

This test suite validates the `StrandsClaude4Driver` implementation for AWS Bedrock Claude 4 Sonnet integration within the Jesse Framework MCP ecosystem. It provides comprehensive testing capabilities for configuration validation, driver lifecycle management, conversation handling, caching mechanisms, and error scenarios. The suite enables developers to verify driver functionality independently from the main MCP server, supporting both structural validation and integration testing. Key semantic entities include `StrandsClaude4Driver`, `Claude4SonnetConfig`, `ConversationMemoryStrategy`, `PromptCache`, `StrandsDriverError`, `asyncio`, `logging`, AWS Bedrock integration, and conversation management patterns. The implementation leverages async/await patterns for non-blocking test execution and context manager protocols for proper resource cleanup.

##### Main Components

The test suite contains five primary test functions: `test_basic_configuration()` validates configuration creation and parameter validation, `test_driver_initialization()` verifies driver lifecycle and context manager usage, `test_conversation_management()` tests conversation operations without API calls, `test_mock_responses()` validates driver structure and error handling, and `test_caching_system()` independently tests the `PromptCache` implementation. Supporting components include `run_all_tests()` for orchestrating test execution and result reporting, `main()` for environment validation and entry point coordination, and comprehensive logging setup with structured output formatting.

###### Architecture & Design

The test architecture follows an async-first design pattern with each test function operating independently while sharing common configuration and logging infrastructure. The suite implements a layered testing approach: structural validation tests verify component initialization and configuration without external dependencies, integration tests validate AWS Bedrock connectivity when credentials are available, and isolated unit tests verify individual components like caching. Error handling uses try-catch blocks with graceful degradation, allowing tests to continue even when external dependencies are unavailable. The design separates concerns between driver functionality testing and infrastructure validation.

####### Implementation Approach

Test execution uses `asyncio.run()` for async coordination with individual test functions returning boolean success indicators. Configuration testing employs factory methods like `create_optimized_for_conversations()`, `create_optimized_for_analysis()`, and `create_optimized_for_performance()` to validate different optimization strategies. Driver testing utilizes async context managers (`async with StrandsClaude4Driver(config)`) to ensure proper resource cleanup. The caching system tests implement time-based validation with `asyncio.sleep()` for TTL verification and sequential operations for eviction testing. Error scenarios are tested through invalid parameter injection and exception capture patterns.

######## External Dependencies & Integration Points

**→ Inbound:**
- `jesse_framework_mcp.llm.strands_agent_driver` - core driver classes and configuration
- `strands` (external library) - Strands Agent SDK for AWS Bedrock integration
- `asyncio` (stdlib) - async execution and sleep operations
- `logging` (stdlib) - structured test output and debugging
- `pathlib.Path` (stdlib) - project root path resolution
- `os` (stdlib) - environment variable access for AWS configuration

**← Outbound:**
- Test execution reports consumed by CI/CD systems
- Validation results for Jesse Framework MCP server integration
- AWS credential validation for deployment environments
- Driver functionality verification for dependent components

**⚡ System role and ecosystem integration:**
- **System Role**: Critical validation component ensuring Strands Claude 4 driver reliability before MCP server deployment
- **Ecosystem Position**: Development and testing infrastructure component supporting the Jesse Framework MCP server's LLM integration capabilities
- **Integration Pattern**: Executed by developers during development, CI/CD pipelines for automated validation, and deployment processes for environment verification

######### Edge Cases & Error Handling

The suite handles missing `strands-agents` package installation with graceful ImportError catching and installation guidance. AWS credential absence is managed through environment variable detection with warning messages rather than test failures. Invalid configuration parameters trigger validation error testing to ensure proper boundary checking. Driver initialization failures are caught and logged as warnings when external dependencies are unavailable, allowing structural tests to continue. The caching system handles TTL expiration, maximum entry limits, and concurrent access scenarios. Test interruption via KeyboardInterrupt is managed with cleanup messaging and proper exit codes.

########## Internal Implementation Details

Logging configuration uses `basicConfig` with timestamp, logger name, level, and message formatting for comprehensive test traceability. Path manipulation adds the project root to `sys.path` using `Path(__file__).parent.parent` for reliable import resolution. Test result tracking uses tuple lists with test names and boolean outcomes for summary generation. The caching test creates a `PromptCache` instance with `max_entries=3` and `ttl_seconds=1` for rapid validation cycles. Configuration validation tests inject invalid parameters like `temperature=1.5` to trigger validation exceptions. AWS environment detection checks both `AWS_ACCESS_KEY_ID` and `AWS_PROFILE` environment variables for credential availability assessment.

########### Code Usage Examples

**Basic test execution pattern:**
```python
# Run the complete test suite
python test_strands_driver.py
```

**Configuration testing demonstrates factory method usage:**
```python
# Create optimized configurations for different use cases
conversation_config = Claude4SonnetConfig.create_optimized_for_conversations()
analysis_config = Claude4SonnetConfig.create_optimized_for_analysis()
performance_config = Claude4SonnetConfig.create_optimized_for_performance()
```

**Driver lifecycle testing with proper resource management:**
```python
# Test driver initialization and cleanup
async with StrandsClaude4Driver(config) as driver:
    conversation_id = "test_conversation_001"
    context = await driver.start_conversation(conversation_id)
    stats = await driver.get_conversation_stats(conversation_id)
```

**Independent cache validation for TTL and eviction behavior:**
```python
# Test caching system independently
cache = PromptCache(max_entries=3, ttl_seconds=1)
await cache.set("test prompt", "test_conversation", "config_hash", "test response")
cached_response = await cache.get("test prompt", "test_conversation", "config_hash")
```

### {PROJECT_ROOT}/jesse-framework-mcp/tests/test_upfront_cache_structure_preparation.py

*Last Updated: 2025-07-05T18:23:26Z*

#### Functional Intent & Features

This test script validates upfront cache structure preparation implementation for the Jesse Framework MCP system, specifically testing the `prepare_cache_structure` method and its integration with `HierarchicalIndexer`. The script provides comprehensive validation of race condition elimination, concurrent cache operations safety, and fallback behavior mechanisms. Key semantic entities include `FileAnalysisCache`, `HierarchicalIndexer`, `IndexingConfig`, `DirectoryContext`, `FileContext`, `ProcessingStatus`, `MockContext`, `MockKnowledgeBuilder`, `tempfile`, `asyncio`, `pathlib.Path`, and `datetime`. The testing framework validates upfront directory creation, concurrent operation safety, hierarchical indexer integration, and on-demand fallback directory creation when structure preparation fails.

##### Main Components

The script contains three primary test functions: `test_cache_structure_preparation()` validates basic cache structure preparation functionality, `test_hierarchical_indexer_integration()` tests integration with the hierarchical indexer including concurrent operations, and `test_fallback_behavior()` validates on-demand directory creation when preparation fails. Supporting components include `MockContext` class for async logging simulation, `MockKnowledgeBuilder` class for avoiding actual LLM calls during testing, `create_directory_context()` helper function for building directory structures from file lists, and `run_all_tests()` orchestration function for comprehensive test execution.

###### Architecture & Design

The testing architecture follows an isolated environment pattern using `tempfile.TemporaryDirectory()` for each test scenario, ensuring no cross-test contamination. The design validates upfront cache structure preparation by creating complex directory hierarchies with nested subdirectories and multiple files per directory. The `MockKnowledgeBuilder` replaces actual LLM processing to focus purely on cache structure mechanics. Each test creates realistic project structures with multiple levels of nesting to validate comprehensive directory preparation and concurrent access patterns.

####### Implementation Approach

The implementation uses recursive directory context building through the `create_directory_context()` helper function that processes file lists into hierarchical `DirectoryContext` structures. Tests validate cache structure preparation by creating complex nested directories (`dir_0/subdir_0`, `dir_1/subdir_1`, etc.) and verifying all necessary cache directories are created upfront. Concurrent safety testing uses `asyncio.gather()` to execute multiple cache operations simultaneously, validating race condition prevention. The approach includes fallback testing where cache operations work without upfront preparation through on-demand directory creation.

######## External Dependencies & Integration Points

**→ Inbound:**
- `jesse_framework_mcp.knowledge_bases.indexing.file_analysis_cache:FileAnalysisCache` - cache structure preparation testing
- `jesse_framework_mcp.knowledge_bases.indexing.hierarchical_indexer:HierarchicalIndexer` - integration validation
- `jesse_framework_mcp.knowledge_bases.models.indexing_config:IndexingConfig` - configuration model testing
- `jesse_framework_mcp.knowledge_bases.models.knowledge_context:DirectoryContext` - context structure validation
- `tempfile` (standard library) - isolated test environment creation
- `asyncio` (standard library) - concurrent operation testing framework
- `pathlib.Path` (standard library) - file system path manipulation

**← Outbound:**
- Test execution results consumed by CI/CD validation systems
- Cache structure validation reports for deployment verification
- Concurrent operation safety metrics for performance monitoring

**⚡ System role and ecosystem integration:**
- **System Role**: Critical validation component ensuring cache structure preparation eliminates race conditions and enables safe concurrent operations in the Jesse Framework MCP knowledge base system
- **Ecosystem Position**: Core testing infrastructure validating the foundation of cache directory management and concurrent access safety
- **Integration Pattern**: Executed by developers and CI systems to validate cache structure reliability before deployment, ensuring hierarchical indexer can safely perform concurrent operations

######### Edge Cases & Error Handling

The tests validate missing cache directories scenarios (should create upfront), concurrent cache operations (should not cause race conditions), hierarchical indexer integration (should prepare structure before processing), and fallback behavior when preparation fails (should create directories on-demand). Error handling includes assertion failures with descriptive messages for missing directories, race condition detection through error message analysis, exception catching with detailed reporting, and comprehensive test result summaries with pass/fail statistics. The tests specifically check for `FileExistsError`, directory creation failures, and concurrent access indicators.

########## Internal Implementation Details

Internal mechanisms include complex directory structure creation with nested loops generating `dir_{i}/subdir_{j}/file_{k}.py` patterns, recursive directory context building that processes file lists into hierarchical structures, and concurrent operation simulation using `asyncio.gather()` for race condition testing. The `MockKnowledgeBuilder` provides realistic processing simulation without LLM calls, while cache path validation ensures all expected directories exist after preparation. Performance measurement tracks directory creation counts and validates cache operation success rates across concurrent executions.

########### Code Usage Examples

Essential cache structure preparation pattern for upfront directory creation:

```python
# This pattern demonstrates upfront cache structure preparation to eliminate race conditions during concurrent operations
# The preparation phase creates all necessary cache directories before any file processing begins
cache = FileAnalysisCache(config)
root_context = await create_directory_context(source_root, files_created)

# Prepare all cache directories upfront
await cache.prepare_cache_structure(root_context, source_root, ctx)

# Verify cache root and subdirectories exist
cache_root = knowledge_dir / "project-base"
assert cache_root.exists(), "Cache root should exist after preparation"
```

Concurrent cache operations safety validation:

```python
# This pattern validates that concurrent cache operations work safely after structure preparation
# Multiple async operations can execute simultaneously without race conditions
async def concurrent_cache_operation(file_path, analysis_content):
    await indexer.knowledge_builder.analysis_cache.cache_analysis(
        file_path, analysis_content, source_root
    )

# Execute multiple concurrent cache operations
tasks = []
for i, test_file in enumerate(test_files):
    task = concurrent_cache_operation(test_file, f"Concurrent analysis {i}")
    tasks.append(task)

await asyncio.gather(*tasks)
```

Directory context creation helper for testing:

```python
# This helper function builds hierarchical DirectoryContext structures from file lists
# It recursively processes directories and creates proper context relationships
def build_directory_context(current_path: Path) -> DirectoryContext:
    file_contexts = []
    subdirectory_contexts = []
    processed_subdirs = set()
    
    # Find files directly in this directory
    for file_path in files:
        if file_path.parent == current_path:
            file_context = FileContext(
                file_path=file_path,
                file_size=file_path.stat().st_size,
                last_modified=datetime.fromtimestamp(file_path.stat().st_mtime)
            )
            file_contexts.append(file_context)
```

---
*Generated: 2025-07-05T18:23:26Z*
*Source Directory: {PROJECT_ROOT}/jesse-framework-mcp/tests*
*Total Files: 18*
*Total Subdirectories: 0*

# End of tests_kb.md