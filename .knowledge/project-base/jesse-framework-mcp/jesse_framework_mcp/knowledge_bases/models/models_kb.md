<!-- ⚠️ DO NOT EDIT MANUALLY! DOCUMENT AUTOMATICALLY GENERATED! ⚠️ -->
<!-- This file is automatically generated by the JESSE Knowledge Base system. -->
<!-- Manual edits will be overwritten during the next generation cycle. -->
<!-- To modify content, update the source files and regenerate the knowledge base. -->
# Directory Knowledge Base {PROJECT_ROOT}/jesse-framework-mcp/jesse_framework_mcp/knowledge_bases/models/

## Global Summary

#### Functional Intent & Features

Comprehensive data model foundation for the Jesse Framework MCP's Knowledge Bases Hierarchical Indexing System, providing type-safe configuration management, runtime context tracking, decision modeling, and execution planning through immutable dataclass structures. The system delivers centralized model definitions enabling consistent data contracts across all indexing components, comprehensive validation at initialization time, and serialization support for external system integration. Enables developers to implement robust knowledge base indexing workflows with structured configuration management, hierarchical processing state tracking, audit trail maintenance, and Plan-then-Execute architecture coordination. Key semantic entities include `IndexingConfig` for system configuration with handler-specific templates, `DirectoryContext` and `FileContext` for hierarchical processing state, `DecisionReport` and `RebuildDecision` for centralized decision logic, `ExecutionPlan` and `AtomicTask` for atomic task execution, `ProcessingStatus` and `IndexingMode` enumerations for state management, `@dataclass(frozen=True)` for immutable structures, `field(default_factory=datetime.now)` for automatic timestamp tracking, and comprehensive validation through `__post_init__()` methods ensuring data integrity across all model types.

##### Main Components

Core configuration models include `IndexingConfig` frozen dataclass providing comprehensive system configuration with hierarchical organization through seven specialized config classes (`FileProcessingConfig`, `ContentFilteringConfig`, `LLMConfig`, `ChangeDetectionConfig`, `ErrorHandlingConfig`, `OutputConfig`, `DebugConfig`), and `IndexingMode` enumeration defining processing strategies. Runtime context models encompass `DirectoryContext` and `FileContext` for hierarchical processing state tracking, `ChangeInfo` for incremental processing change detection, `ProcessingStats` for performance metrics, and `IndexingStatus` for overall operation coordination. Decision models provide `DecisionReport` for comprehensive decision aggregation, `RebuildDecision` and `DeletionDecision` for immutable decision outcomes, and supporting enumerations `DecisionOutcome` and `DecisionReason` for structured classification. Execution planning models include `ExecutionPlan` for atomic task coordination, `AtomicTask` for complete execution specification, `TaskType` enumeration for task classification, and `ExecutionResults` for comprehensive execution tracking. Package initialization through `__init__.py` provides centralized exports with 19 model classes ensuring controlled public API surface and clean dependency management.

###### Architecture & Design

Implements immutable data model architecture using frozen dataclasses ensuring thread safety and preventing runtime modifications across all configuration and decision models. Uses hierarchical configuration organization with specialized config classes handling specific domains while maintaining backward compatibility through property accessors. Employs comprehensive validation patterns with `__post_init__()` methods performing initialization-time validation and descriptive error reporting for invalid configurations. Implements Plan-then-Execute separation through distinct model categories: configuration models for system setup, runtime context models for processing state, decision models for audit trails, and execution models for atomic task management. Uses type-safe enumeration design preventing ambiguous state representation and enabling clear outcome validation. Follows composition patterns with specialized classes handling their specific domains while maintaining clear boundaries between different model types. Implements caching strategies in execution planning models with lazy computation and cache invalidation for performance optimization.

####### Implementation Approach

Uses frozen dataclass pattern with `@dataclass(frozen=True)` ensuring immutability and audit trail integrity while providing automatic initialization and field validation. Implements default factory pattern with `field(default_factory=datetime.now)` and `field(default_factory=dict)` for timestamp generation and collection initialization. Employs comprehensive parameter validation in `__post_init__()` methods with descriptive error messages and type checking for all configuration parameters. Uses dictionary-based serialization with `to_dict()` and `from_dict()` methods supporting JSON compatibility through proper handling of complex types like sets, enums, and Path objects. Implements efficient filtering logic using set membership for excluded extensions and directories with performance-optimized file size validation through `Path.stat()`. Uses property-based backward compatibility access preserving existing API contracts while enabling hierarchical configuration organization. Employs topological sorting for dependency resolution in execution planning with circular dependency detection using depth-first search algorithms.

######## External Dependencies & Integration Points

**→ Inbound:**
- `dataclasses` (external library) - Frozen dataclass implementation for immutable model structures with automatic initialization
- `pathlib.Path` (external library) - Cross-platform path operations and filesystem metadata access for configuration validation
- `datetime` (external library) - Timestamp tracking and processing duration calculations for context and execution models
- `typing` (external library) - Comprehensive type annotations for Optional, List, Dict, Set, Any supporting static analysis
- `enum.Enum` (external library) - String-based enumeration definitions for ProcessingStatus, IndexingMode, TaskType classifications
- `jesse_framework_mcp.llm.strands_agent_driver.models:Claude4SonnetModel` - Official Claude 4 Sonnet model ID for LLM configuration
- `jesse_framework_mcp.helpers.path_utils:get_project_root` - Project root detection for automatic knowledge directory defaulting
- `logging` (external library) - Structured logging for model validation and execution analysis

**← Outbound:**
- `../indexing/hierarchical_indexer.py:HierarchicalIndexer` - Primary consumer of configuration and context models for workflow orchestration
- `../indexing/knowledge_builder.py:KnowledgeBuilder` - Consumer using context models for processing state and LLM configuration
- `../indexing/rebuild_decision_engine.py:RebuildDecisionEngine` - Consumer using decision models for centralized decision logic
- `../indexing/plan_generator.py:PlanGenerator` - Consumer using execution planning models for atomic task creation
- `../indexing/execution_engine.py:ExecutionEngine` - Consumer using execution models for task processing and dependency resolution
- `../indexing/config_manager.py:IndexingConfigManager` - Consumer using serialization methods for configuration persistence
- `*.indexing-config.json` - Generated configuration files from IndexingConfig serialization
- `external_monitoring_systems/` - Consumers of ProcessingStats and ExecutionResults for performance analysis

**⚡ System role and ecosystem integration:**
- **System Role**: Foundational data model layer serving as the central type system and data contract foundation for the entire Jesse Framework MCP knowledge base indexing architecture
- **Ecosystem Position**: Core infrastructure component providing immutable, type-safe data structures that enable consistent behavior across all indexing components while supporting serialization for external system integration
- **Integration Pattern**: Used by all indexing components through dependency injection for configuration and state management, consumed by configuration managers for persistence, integrated with monitoring systems through serialization interfaces, and serving as the primary data contract between plan generation and execution systems

######### Edge Cases & Error Handling

Implements comprehensive validation scenarios including negative or zero values for file sizes, batch parameters, and concurrency limits with descriptive `ValueError` exceptions in configuration models. Handles missing decisions through `get_decision_for_path()` returning `None` when no decision exists for specified path, enabling graceful handling of incomplete decision scenarios. Manages filesystem access errors during file size validation with `OSError` and `FileNotFoundError` catching, returning `False` for inaccessible files to prevent processing failures. Provides safety validation for deletion decisions through `is_safe_to_delete` boolean flag and `backup_recommended` flag preventing accidental data loss. Implements comprehensive task validation through `_validate_task()` with task-type-specific checks ensuring required metadata is present, raising descriptive errors for missing parameters. Handles dependency validation with circular dependency detection using depth-first search, returning detailed error lists for targeted fixes. Uses immutable design preventing accidental modification of decision and configuration objects after creation, ensuring audit trail integrity even in error scenarios.

########## Internal Implementation Details

Uses `object.__setattr__()` to modify frozen dataclass fields during initialization when setting default knowledge directory in `IndexingConfig.__post_init__()`. Implements property accessors providing backward compatibility by delegating to hierarchical configuration group attributes while maintaining new structure organization. Uses dictionary-based decision storage with `Dict[Path, RebuildDecision]` enabling efficient O(1) path-based decision lookup and deduplication. Employs set-based action lists with `Set[Path]` for files_to_rebuild and files_to_delete ensuring unique operations and preventing duplicate actions. Implements caching mechanism in execution planning using `Optional` fields initialized to `None` with property-based lazy computation and cache invalidation through `_invalidate_caches()`. Uses iterative dependency level calculation with remaining task tracking, processing tasks with no unresolved dependencies in each iteration. Employs comprehensive statistics calculation through list comprehensions and filtering operations providing real-time decision analysis and monitoring capabilities. Implements path truncation with smart character counting and "..." prefix handling for display optimization in execution planning.

########### Usage Examples

Essential configuration model usage demonstrates comprehensive system setup with validation and automatic defaults. This pattern shows how to create type-safe configurations with hierarchical organization and automatic knowledge directory setting.

```python
# Comprehensive configuration creation with hierarchical organization and validation
from jesse_framework_mcp.knowledge_bases.models import IndexingConfig, IndexingMode
from jesse_framework_mcp.knowledge_bases.models.indexing_config import FileProcessingConfig, LLMConfig

config = IndexingConfig(
    handler_type="project-base",
    indexing_mode=IndexingMode.INCREMENTAL,
    file_processing=FileProcessingConfig(max_file_size=5*1024*1024, batch_size=10),
    llm_config=LLMConfig(temperature=0.2, max_tokens=15000)
)

# Configuration automatically validates and sets knowledge directory
print(f"Knowledge directory: {config.knowledge_output_directory}")
should_process = config.should_process_file(Path("src/module.py"))
```

Runtime context model integration showcases hierarchical processing state management with comprehensive tracking. This approach demonstrates creating immutable context structures for processing coordination and progress reporting.

```python
# Runtime context creation with hierarchical processing state tracking
from jesse_framework_mcp.knowledge_bases.models import (
    DirectoryContext, FileContext, ProcessingStatus, ChangeInfo, ChangeType
)

# Create file context with change detection and processing state
file_context = FileContext(
    file_path=Path("src/main.py"),
    file_size=1024,
    last_modified=datetime.now(),
    processing_status=ProcessingStatus.COMPLETED,
    knowledge_content="LLM analysis result",
    change_info=ChangeInfo(change_type=ChangeType.MODIFIED)
)

# Build directory context with file aggregation and readiness checking
directory_context = DirectoryContext(
    directory_path=Path("src/"),
    file_contexts=[file_context],
    processing_status=ProcessingStatus.COMPLETED
)

print(f"Directory ready: {directory_context.is_ready_for_summary}")
print(f"Completion: {directory_context.completion_percentage}%")
```

Decision and execution model coordination demonstrates Plan-then-Execute architecture with comprehensive audit trails. This pattern shows creating immutable decision objects and converting them to atomic execution tasks with dependency management.

```python
# Decision modeling with execution planning for Plan-then-Execute workflows
from jesse_framework_mcp.knowledge_bases.models import (
    DecisionReport, RebuildDecision, DecisionOutcome, DecisionReason,
    ExecutionPlan, AtomicTask, TaskType, ExecutionResults
)

# Create comprehensive decision report with structured outcomes
report = DecisionReport()
decision = RebuildDecision(
    path=Path("src/main.py"),
    outcome=DecisionOutcome.REBUILD,
    reason=DecisionReason.CACHE_STALE,
    reasoning_text="Source file is newer than analysis cache",
    metadata={"file_size": 1024, "cache_age": 3600}
)
report.add_rebuild_decision(decision)

# Generate execution plan with atomic tasks and dependency validation
plan = ExecutionPlan(source_root=Path("/project"))
task = AtomicTask(
    task_id="analyze_main_py",
    task_type=TaskType.ANALYZE_FILE_LLM,
    target_path=Path("src/main.py"),
    estimated_duration=30.0,
    metadata={"file_size": 1024, "source_root": "/project"}
)
plan.add_task(task)

# Validate dependencies and execute with comprehensive tracking
validation_errors = plan.validate_dependencies()
if not validation_errors:
    results = ExecutionResults(plan_id=plan.plan_id)
    print(f"Plan valid: {plan.total_estimated_duration:.1f}s estimated")
```

## Subdirectory Knowledge Integration

*No subdirectories processed*

## File Knowledge Integration

### {PROJECT_ROOT}/jesse-framework-mcp/jesse_framework_mcp/knowledge_bases/models/__init__.py

*Last Updated: 2025-07-06T23:07:18Z*

#### Functional Intent & Features

This file serves as the models package initialization module for the Knowledge Bases Hierarchical Indexing System, providing centralized exports of all data models, configuration classes, and context structures used throughout the hierarchical indexing workflow and FastMCP integration. The module exports comprehensive model collections including `IndexingConfig` and `IndexingMode` for configuration management, `DirectoryContext` and `FileContext` for runtime context tracking, and specialized models like `DecisionReport`, `RebuildDecision`, and `ExecutionPlan` for decision-making and execution planning. Key semantic entities include the `__all__` list defining the public API surface with 19 exported classes, type-safe data structures supporting serialization through dataclasses or Pydantic models, and clear separation between configuration models and runtime context models. The system implements centralized model exports for clean dependency management, ensures immutable configurations for thread safety where possible, and provides comprehensive validation at initialization time for all configuration and runtime models.

##### Main Components

The file contains four primary import groups representing different model categories within the knowledge indexing system. The configuration models group includes `IndexingConfig` for system configuration and `IndexingMode` enumeration for processing mode selection. The runtime context models group encompasses `DirectoryContext` and `FileContext` for hierarchical processing state, along with supporting classes `ChangeInfo`, `IndexingStatus`, `ProcessingStats`, `ProcessingStatus`, and `ChangeType` for comprehensive state tracking. The decision models group provides `DecisionReport`, `RebuildDecision`, and `DeletionDecision` for centralized decision logic, with `DecisionOutcome` and `DecisionReason` enumerations for structured decision classification. The execution planning models group includes `ExecutionPlan`, `AtomicTask`, `TaskType`, and `ExecutionResults` for Plan-then-Execute architecture implementation. The `__all__` list explicitly defines 19 exported classes ensuring controlled public API surface and preventing accidental exposure of internal implementation details.

###### Architecture & Design

The architecture implements a centralized export pattern with clear separation between different model categories to prevent circular dependencies and enable clean dependency management. The design follows type-safe data structure principles using dataclasses or Pydantic models for comprehensive serialization support and validation capabilities. The package structure maintains immutable configurations where possible for thread safety, with configuration validation happening at initialization time to catch errors early. The export organization groups related models together while maintaining clear boundaries between configuration models, runtime context models, decision models, and execution planning models. The `__all__` declaration provides explicit control over the public API surface, ensuring only intended classes are exposed and preventing accidental imports of internal implementation details. The module structure supports async operations for runtime context models while maintaining synchronous interfaces for configuration models.

####### Implementation Approach

The implementation uses selective imports from four internal modules with explicit public API definition through the comprehensive `__all__` list containing 19 model classes. The import strategy organizes models by functional category: configuration models from `indexing_config`, runtime context models from `knowledge_context`, decision models from `rebuild_decisions`, and execution planning models from `execution_plan`. The module follows Python package initialization conventions with comprehensive docstring documentation explaining the package purpose and model organization. The approach ensures all exported models support serialization requirements through dataclass or Pydantic model implementation, with validation occurring at initialization time for configuration models and runtime validation for context models. The implementation maintains strict separation between different model types to prevent circular dependencies while enabling comprehensive model access through a single import point.

######## External Dependencies & Integration Points

**→ Inbound:**
- `.indexing_config.IndexingConfig` - System configuration data model with validation
- `.indexing_config.IndexingMode` - Processing mode enumeration for configuration
- `.knowledge_context.DirectoryContext` - Directory processing state and file context aggregation
- `.knowledge_context.FileContext` - Individual file processing state and metadata
- `.knowledge_context.ChangeInfo` - File change tracking information
- `.knowledge_context.IndexingStatus` - Overall indexing status enumeration
- `.knowledge_context.ProcessingStats` - Performance metrics and statistics
- `.knowledge_context.ProcessingStatus` - Individual processing status enumeration
- `.knowledge_context.ChangeType` - File change type classification
- `.rebuild_decisions.DecisionReport` - Comprehensive decision analysis results
- `.rebuild_decisions.RebuildDecision` - Individual rebuild decision outcomes
- `.rebuild_decisions.DeletionDecision` - Individual deletion decision outcomes
- `.rebuild_decisions.DecisionOutcome` - Decision outcome enumeration
- `.rebuild_decisions.DecisionReason` - Decision reasoning classification
- `.execution_plan.ExecutionPlan` - Complete execution planning with task dependencies
- `.execution_plan.AtomicTask` - Individual atomic task representation
- `.execution_plan.TaskType` - Task type enumeration for execution dispatch
- `.execution_plan.ExecutionResults` - Execution outcome tracking and metrics

**← Outbound:**
- `../indexing/hierarchical_indexer.py` - Primary consumer importing configuration and context models
- `../indexing/knowledge_builder.py` - Consumer using context models for processing state
- `../indexing/rebuild_decision_engine.py` - Consumer using decision models for structured outcomes
- `../indexing/plan_generator.py` - Consumer using execution planning models for task creation
- `../indexing/execution_engine.py` - Consumer using execution models for task processing
- `../handlers/` - MCP handlers importing models for knowledge base operations
- `external_consumers/` - External systems importing models for integration

**⚡ System role and ecosystem integration:**
- **System Role**: Central model registry within the Jesse Framework MCP knowledge indexing system, serving as the primary import interface for all data models, configuration classes, and context structures
- **Ecosystem Position**: Foundational package providing the core data contracts and type definitions used throughout the hierarchical indexing workflow, ensuring consistent model usage across all components
- **Integration Pattern**: Used by indexing components for model imports, consumed by MCP handlers for knowledge base operations, and integrated with external systems requiring structured data access to knowledge indexing models

######### Edge Cases & Error Handling

The module handles import failures gracefully through Python's standard import mechanism, where missing dependencies would raise `ImportError` exceptions at package initialization time with clear error messages about missing model modules. Circular dependency prevention is managed through the clear separation of model categories and explicit import structure avoiding cross-references between different model types. The `__all__` list prevents accidental exposure of internal implementation details that could lead to dependency issues in consuming code, ensuring only intended model classes are available for import. Model validation errors are handled at the individual model level rather than at the package initialization level, ensuring that import failures provide clear error messages about specific model validation issues. The centralized export pattern enables consistent error handling across all model types while maintaining clear boundaries between configuration validation, runtime context validation, and execution model validation.

########## Internal Implementation Details

The package uses standard Python `__init__.py` conventions with explicit imports from four internal modules following the pattern `from .module_name import ClassName1, ClassName2`. The `__all__` list maintains exactly 19 exported model classes ensuring controlled public API surface and preventing internal implementation leakage through comprehensive class enumeration. The module header includes comprehensive GenAI tool directives with change history tracking and design principle documentation following the established Jesse Framework patterns. The import structure avoids wildcard imports (`from module import *`) in favor of explicit class imports for better dependency tracking, IDE support, and import error clarity. The docstring follows standard Python documentation conventions explaining the package purpose and model organization for both human developers and automated documentation generation tools. The export organization groups models logically while maintaining alphabetical ordering within each category for consistent and predictable import behavior.

########### Code Usage Examples

**Comprehensive model imports for knowledge indexing operations:** This example demonstrates importing all necessary models for complete knowledge base indexing workflows with proper model separation and usage patterns.

```python
from jesse_framework_mcp.knowledge_bases.models import (
    IndexingConfig, IndexingMode,
    DirectoryContext, FileContext, ProcessingStatus,
    DecisionReport, RebuildDecision, DecisionOutcome,
    ExecutionPlan, AtomicTask, TaskType
)

# Configure indexing with validation
config = IndexingConfig(
    source_directory=Path("/project/src"),
    indexing_mode=IndexingMode.INCREMENTAL,
    max_concurrent_operations=4
)
```

**Runtime context model usage for processing state tracking:** This example shows using context models for hierarchical processing state management with comprehensive status tracking and change detection.

```python
from jesse_framework_mcp.knowledge_bases.models import (
    DirectoryContext, FileContext, ChangeInfo, ChangeType
)

# Create file context with change tracking
file_context = FileContext(
    file_path=Path("src/main.py"),
    processing_status=ProcessingStatus.PENDING,
    change_info=ChangeInfo(change_type=ChangeType.MODIFIED)
)

# Build directory context with file aggregation
directory_context = DirectoryContext(
    directory_path=Path("src/"),
    file_contexts=[file_context],
    processing_status=ProcessingStatus.IN_PROGRESS
)
```

**Decision and execution model integration for Plan-then-Execute workflows:** This example demonstrates integrating decision models with execution planning models for comprehensive workflow orchestration and audit trail maintenance.

```python
from jesse_framework_mcp.knowledge_bases.models import (
    DecisionReport, RebuildDecision, DecisionOutcome,
    ExecutionPlan, AtomicTask, TaskType, ExecutionResults
)

# Create decision report with structured outcomes
report = DecisionReport()
decision = RebuildDecision(
    path=Path("src/main.py"),
    outcome=DecisionOutcome.REBUILD,
    reasoning_text="File analysis cache is stale"
)
report.add_rebuild_decision(decision)

# Generate execution plan from decisions
plan = ExecutionPlan()
task = AtomicTask(
    task_id="analyze_main_py",
    task_type=TaskType.ANALYZE_FILE_LLM,
    target_path=Path("src/main.py")
)
plan.add_task(task)
```

### {PROJECT_ROOT}/jesse-framework-mcp/jesse_framework_mcp/knowledge_bases/models/execution_plan.py

*Last Updated: 2025-07-06T23:07:18Z*

#### Functional Intent & Features

This file defines execution planning models for the Plan-then-Execute architecture in the Knowledge Bases Hierarchical Indexing System, enabling clear separation between decision-making and execution phases with comprehensive debuggability and task dependency management. The module implements atomic task definition through `AtomicTask` dataclass with complete execution specification, comprehensive execution planning via `ExecutionPlan` with dependency resolution and task ordering, and detailed execution tracking through `ExecutionResults` for performance analysis. Key semantic entities include `TaskType` enumeration with values like `ANALYZE_FILE_LLM`, `CREATE_DIRECTORY_KB`, and `DELETE_ORPHANED_FILE` for structured task classification, `@dataclass` decorators for immutable execution plans, `field(default_factory=datetime.now)` for automatic timestamp tracking, and `validate_dependencies()` method implementing directed acyclic graph validation. The system provides rich metadata support enabling detailed task analysis without execution, implements topological sorting for dependency-respecting execution order, and offers comprehensive preview functionality through `ExecutionPlan.preview()` generating human-readable execution plans for debugging and verification workflows.

##### Main Components

The file contains four primary components implementing the execution planning architecture. The `TaskType` enumeration defines comprehensive atomic task types including file analysis operations (`ANALYZE_FILE_LLM`, `SKIP_FILE_CACHED`), directory knowledge operations (`CREATE_DIRECTORY_KB`, `SKIP_DIRECTORY_FRESH`), cleanup operations (`DELETE_ORPHANED_FILE`, `DELETE_ORPHANED_DIRECTORY`), structure operations (`CREATE_CACHE_STRUCTURE`), and validation operations (`VERIFY_CACHE_FRESHNESS`, `VERIFY_KB_FRESHNESS`). The `AtomicTask` dataclass represents single atomic units of work with complete execution specification including task identity fields, dependency management through task ID lists, performance estimation with duration and priority, and task-specific parameters embedded in metadata dictionaries. The `ExecutionPlan` dataclass provides complete execution planning with ordered task lists, dependency validation, analysis capabilities, and cached performance metrics. The `ExecutionResults` dataclass tracks comprehensive execution outcomes with task completion status, performance metrics including LLM calls and file operations, and detailed success/failure analysis for optimization and debugging purposes.

###### Architecture & Design

The architecture implements Plan-then-Execute separation with immutable execution plans ensuring consistent task execution behavior across multiple runs. The design follows atomic task principles where each `AtomicTask` contains complete execution specification eliminating external state dependencies through comprehensive metadata embedding. The `ExecutionPlan` uses cached analysis pattern with lazy computation of task counts, dependency levels, and duration estimates, invalidating caches when plans are modified through `_invalidate_caches()`. Error handling architecture separates validation errors from execution errors, with `validate_dependencies()` performing comprehensive dependency analysis including circular dependency detection using depth-first search. The dependency management system uses task ID references enabling flexible execution ordering algorithms and parallel execution identification through `get_parallel_execution_groups()`. The preview and analysis system provides multiple views including task categorization, dependency visualization, and resource estimation without performing actual execution, supporting comprehensive debugging and optimization workflows.

####### Implementation Approach

The implementation uses dataclass-based immutable objects with `@dataclass` decorators and `field(default_factory=list)` for automatic collection initialization. Task validation employs `__post_init__()` hooks with task-type-specific validation ensuring required metadata is present before execution, raising descriptive errors for missing parameters. Dependency resolution implements topological sorting through iterative level calculation, assigning dependency levels to enable parallel execution identification and proper task ordering. The caching strategy uses optional fields with `None` initialization and lazy computation, calculating expensive analysis only when accessed and invalidating when plans are modified. Path display optimization uses smart truncation through `_truncate_path_smart()` limiting displayed paths to 50 characters while preserving important path information with "..." prefix truncation. Performance estimation integrates duration tracking, LLM call counting, and resource utilization metrics enabling accurate progress reporting and execution planning. The preview system generates comprehensive human-readable output with emoji-based task type visualization, dependency analysis, and detailed task breakdowns for debugging and verification purposes.

######## External Dependencies & Integration Points

**→ Inbound:**
- `pathlib.Path` (external library) - Cross-platform path operations and file metadata for task target specification
- `datetime.datetime` (external library) - Timestamp and duration tracking for task execution timing
- `datetime.timedelta` (external library) - Duration calculations for performance analysis and estimation
- `typing.Dict` (external library) - Type annotations for comprehensive static analysis and metadata structure
- `typing.List` (external library) - Type annotations for task collections and dependency management
- `typing.Optional` (external library) - Type annotations for nullable fields and optional metadata
- `typing.Any` (external library) - Type annotations for flexible metadata content and task parameters
- `typing.Set` (external library) - Type annotations for dependency validation and circular dependency detection
- `typing.Tuple` (external library) - Type annotations for structured data like failed task records
- `enum.Enum` (external library) - Task type enumeration for structured task classification
- `dataclasses.dataclass` (external library) - Immutable execution plan creation with validation
- `dataclasses.field` (external library) - Default factory configuration for automatic initialization
- `logging` (external library) - Structured logging for execution analysis and debugging

**← Outbound:**
- `../indexing/plan_generator.py:PlanGenerator` - Primary consumer creating ExecutionPlan objects from decisions
- `../indexing/execution_engine.py:ExecutionEngine` - Consumer executing AtomicTask objects with dependency resolution
- `../indexing/hierarchical_indexer.py:HierarchicalIndexer` - Consumer coordinating plan generation and execution workflows
- `execution_plans/` - Serialized ExecutionPlan objects for debugging and analysis workflows
- `execution_results/` - Generated ExecutionResults objects for performance analysis and optimization
- `task_metadata/` - Comprehensive task metadata for independent execution and troubleshooting

**⚡ System role and ecosystem integration:**
- **System Role**: Foundational execution model layer within the Jesse Framework MCP Plan-then-Execute architecture, providing structured task representation and execution planning capabilities for all knowledge base indexing operations
- **Ecosystem Position**: Core model component serving as the primary data contract between plan generation and execution systems, ensuring atomic task definition and dependency management across the indexing workflow
- **Integration Pattern**: Used by plan generators for structured task creation, consumed by execution engines for atomic task processing, and integrated with monitoring systems for comprehensive execution tracking and performance analysis

######### Edge Cases & Error Handling

The system implements comprehensive task validation through `_validate_task()` with task-type-specific checks ensuring required metadata is present, raising `ValueError` exceptions with descriptive messages for missing parameters like `file_size`, `source_root`, or `is_safe_to_delete`. Dependency validation handles missing task references and circular dependencies through `validate_dependencies()` using depth-first search to detect cycles and returning detailed error lists for targeted fixes. Path display handles edge cases through graceful fallback in `_get_display_path()` where relative path calculation failures fall back to basename display, and smart truncation handles extremely short maximum lengths by returning truncated filenames. Execution plan modification safety uses cache invalidation through `_invalidate_caches()` ensuring cached analysis remains consistent when tasks are added or modified. Task ordering handles circular dependencies by breaking with error logging when topological sorting cannot proceed, preventing infinite loops during execution order calculation. Performance estimation handles missing or invalid duration values by defaulting to zero and provides fallback emoji mapping for unknown task types in preview generation.

########## Internal Implementation Details

The task validation system uses dictionary-based required key checking with list comprehensions: `missing_keys = [key for key in required_keys if key not in self.metadata]` providing efficient validation for task-type-specific requirements. Dependency level calculation uses iterative algorithm with remaining task tracking, processing tasks with no unresolved dependencies in each iteration and incrementing level counters until all tasks are assigned levels. The caching mechanism uses `Optional` fields initialized to `None` with property-based lazy computation, checking cache validity before expensive calculations and storing results for subsequent access. Path truncation implements upfront truncation with character counting: `chars_to_keep = max_length - 3` reserving space for "..." prefix and ensuring total length constraints are respected. Task ordering uses multi-key sorting with tuple-based comparison: `(dependency_level, -priority, created_at)` ensuring proper execution order respecting dependencies, priorities, and creation timing. The preview system uses emoji mapping dictionaries and string formatting with consistent section headers, providing comprehensive execution plan visualization with task counts, dependency analysis, and detailed task listings for debugging and verification workflows.

########### Code Usage Examples

**Creating atomic tasks with comprehensive validation and metadata:** This example demonstrates creating validated atomic tasks with complete execution specification and task-type-specific metadata for independent execution.

```python
# Create LLM analysis task with required metadata
llm_task = AtomicTask(
    task_id="analyze_main_py",
    task_type=TaskType.ANALYZE_FILE_LLM,
    target_path=Path("src/main.py"),
    dependencies=["cleanup_orphaned", "create_cache_structure"],
    estimated_duration=30.0,
    priority=50,
    metadata={
        "file_size": 1024,
        "last_modified": "2025-01-01T12:00:00",
        "source_root": "/project/root"
    }
)

# Task validation occurs automatically in __post_init__
print(f"Task created: {llm_task.description}")
print(f"Is expensive: {llm_task.is_expensive}")
```

**Building execution plans with dependency validation and analysis:** This example shows creating comprehensive execution plans with dependency validation, task ordering, and parallel execution analysis for optimal resource utilization.

```python
# Create execution plan and add tasks
plan = ExecutionPlan(source_root=Path("/project/root"))
plan.add_task(llm_task)
plan.add_task(cleanup_task)

# Validate dependencies and get execution order
validation_errors = plan.validate_dependencies()
if not validation_errors:
    execution_order = plan.get_execution_order()
    parallel_groups = plan.get_parallel_execution_groups()
    
    print(f"Plan valid: {len(execution_order)} tasks in {len(parallel_groups)} levels")
    print(f"Estimated duration: {plan.total_estimated_duration:.1f}s")
    print(f"Expensive tasks: {plan.expensive_task_count}")
else:
    print(f"Validation errors: {validation_errors}")
```

**Comprehensive execution tracking and performance analysis:** This example demonstrates detailed execution result tracking with performance metrics, success rate calculation, and comprehensive reporting for optimization purposes.

```python
# Track execution results with comprehensive metrics
results = ExecutionResults(
    plan_id=plan.plan_id,
    execution_start=datetime.now()
)

# Record task outcomes during execution
results.add_completed_task("analyze_main_py")
results.add_failed_task("create_kb_utils", "LLM timeout error")
results.llm_calls_made = 5
results.files_processed = 10

# Complete execution and generate summary
results.complete_execution()
summary = results.get_summary()
print(f"Success rate: {results.success_rate:.1%}")
print(f"Total duration: {results.total_duration:.1f}s")
print(summary)
```

### {PROJECT_ROOT}/jesse-framework-mcp/jesse_framework_mcp/knowledge_bases/models/indexing_config.py

*Last Updated: 2025-07-06T23:07:18Z*

#### Functional Intent & Features

This file provides the comprehensive configuration data model for the Jesse Framework MCP's Knowledge Bases Hierarchical Indexing System, enabling type-safe parameter management for indexing operations, LLM integration, and specialized handler support. The system delivers immutable configuration with validation at initialization through the `IndexingConfig` frozen dataclass, hierarchical configuration groups (`FileProcessingConfig`, `ContentFilteringConfig`, `LLMConfig`, `ChangeDetectionConfig`, `ErrorHandlingConfig`, `OutputConfig`, `DebugConfig`), and integration with `Claude4SonnetModel` from `strands_agent_driver`. Key semantic entities include `IndexingMode` enum with values `FULL`, `FULL_KB_REBUILD`, and `INCREMENTAL`, configuration serialization via `to_dict()` and `from_dict()` methods, filtering logic through `should_process_file()` and `should_process_directory()` methods, automatic knowledge directory defaulting to `{PROJECT_ROOT}/.knowledge/` via `get_project_root()` integration, and convenience factory method `load_for_handler()` supporting three handler types: `project-base`, `git-clones`, and `pdf-knowledge` with comprehensive parameter coverage including file processing limits, content filtering rules, LLM parameters, change detection settings, error handling configuration, output management, and debug capabilities.

##### Main Components

The file contains the `IndexingMode` enum defining three processing strategies, seven specialized configuration dataclasses (`FileProcessingConfig`, `ContentFilteringConfig`, `LLMConfig`, `ChangeDetectionConfig`, `ErrorHandlingConfig`, `OutputConfig`, `DebugConfig`) for hierarchical organization, and the primary `IndexingConfig` frozen dataclass serving as the comprehensive configuration container. Core methods include `__post_init__()` for validation and default setting, `should_process_file()` and `should_process_directory()` for filtering logic, `to_dict()` and `from_dict()` for serialization support, and the class method `load_for_handler()` for configuration manager integration. The configuration system provides backward compatibility through property accessors for all configuration parameters while maintaining the new hierarchical structure.

###### Architecture & Design

The architecture implements a hierarchical frozen dataclass pattern with focused configuration groups for logical organization and maintainability. The design uses immutable configuration ensuring thread safety and preventing runtime modifications, comprehensive validation at initialization time through `__post_init__()`, and clear separation of concerns across seven configuration domains. The system employs composition patterns with specialized configuration classes handling their specific domains, property-based backward compatibility access preserving existing API contracts, and integration patterns with external systems through serialization methods. The architecture includes defensive parameter validation preventing runtime errors, automatic default setting for knowledge output directory following JESSE Framework conventions, and type-safe configuration creation from external data sources.

####### Implementation Approach

The implementation uses frozen dataclasses with `field(default_factory=...)` for complex default values, comprehensive parameter validation in `__post_init__()` with descriptive error messages, and hierarchical configuration group instantiation for logical organization. Configuration serialization employs dictionary conversion with proper handling of complex types like sets and enums, while deserialization processes hierarchical data into appropriate dataclass instances with type conversion. The filtering system implements performance-optimized checks using set membership for excluded extensions and directories, file size validation through `Path.stat()` with error handling, and hierarchical exclusion support for project-base specific filtering. The system uses `object.__setattr__()` for modifying frozen dataclass fields during initialization and integrates with project root detection for automatic knowledge directory configuration.

######## External Dependencies & Integration Points

**→ Inbound:**
- `jesse_framework_mcp.llm.strands_agent_driver.models:Claude4SonnetModel` - official Claude 4 Sonnet model ID for LLM configuration
- `jesse_framework_mcp.helpers.path_utils:get_project_root` - project root detection for automatic knowledge directory defaulting
- `dataclasses` (external library) - frozen dataclass implementation for immutable configuration
- `pathlib.Path` (external library) - path validation and manipulation for file system operations
- `typing` (external library) - type annotations and validation for configuration parameters
- `enum.Enum` (external library) - enumeration support for `IndexingMode` values

**← Outbound:**
- `knowledge_bases/indexing/hierarchical_indexer.py:HierarchicalIndexer` - consumes configuration for orchestration behavior
- `knowledge_bases/indexing/change_detector.py:ChangeDetector` - uses configuration for timestamp tolerance and processing mode
- `knowledge_bases/indexing/knowledge_builder.py:KnowledgeBuilder` - consumes LLM configuration and processing parameters
- `knowledge_bases/indexing/config_manager.py:IndexingConfigManager` - uses `from_dict()` and `to_dict()` for configuration persistence
- `*.indexing-config.json` - serialized configuration files generated from this model

**⚡ System role and ecosystem integration:**
- **System Role**: Central configuration foundation for the Jesse Framework MCP knowledge base indexing system, serving as the authoritative parameter source for all indexing operations and LLM integration
- **Ecosystem Position**: Core infrastructure component that enables type-safe configuration management across the entire indexing architecture, essential for consistent behavior and validation
- **Integration Pattern**: Used by all indexing components through dependency injection, consumed by configuration managers for persistence, and integrated with external systems through serialization interfaces

######### Edge Cases & Error Handling

The system handles comprehensive validation scenarios including negative or zero values for file sizes, batch parameters, and concurrency limits with descriptive `ValueError` exceptions. Temperature validation ensures LLM parameters remain within valid 0.0-1.0 range, while retry configuration validates non-negative values for resilient operation. File processing edge cases include handling `OSError` and `FileNotFoundError` during file size checks, returning `False` for inaccessible files to prevent processing failures. Configuration serialization handles `None` values for optional paths, converts sets to lists for JSON compatibility, and processes enum values to string representation. The `from_dict()` method provides robust handling of missing configuration sections with sensible defaults, proper type conversion for complex parameters, and validation through standard dataclass initialization ensuring configuration consistency.

########## Internal Implementation Details

The configuration system uses `object.__setattr__()` to modify the frozen `output_config` field during `__post_init__()` when setting the default knowledge directory. Property accessors provide backward compatibility by delegating to hierarchical configuration group attributes while maintaining the new structure. Serialization employs comprehensive dictionary conversion with proper handling of `Path` objects through `str()` conversion and set-to-list conversion for JSON compatibility. The `from_dict()` method processes hierarchical configuration data by extracting nested dictionaries, creating appropriate dataclass instances, and handling optional parameters with proper `None` value processing. File filtering uses `Path.suffix.lower()` for case-insensitive extension comparison and `Path.stat().st_size` for file size validation with exception handling. Directory filtering implements hierarchical exclusion checking by first validating against base exclusions then checking project-base specific exclusions when available.

########### Code Usage Examples

This example demonstrates basic configuration creation with validation and automatic knowledge directory setting:

```python
# Basic configuration instantiation with automatic validation and default knowledge directory
config = IndexingConfig(
    handler_type="project-base",
    file_processing=FileProcessingConfig(max_file_size=5*1024*1024, batch_size=10),
    llm_config=LLMConfig(temperature=0.2, max_tokens=15000)
)
# Automatically sets knowledge_output_directory to {PROJECT_ROOT}/.knowledge/
print(f"Knowledge directory: {config.knowledge_output_directory}")
```

This example shows configuration serialization and deserialization for persistence:

```python
# Configuration serialization for JSON persistence and external system integration
config_dict = config.to_dict()
# Save to JSON file or send to external system

# Configuration deserialization from hierarchical dictionary data
loaded_config = IndexingConfig.from_dict(config_dict)
# Maintains all validation and type safety
```

This example demonstrates file and directory filtering using configuration rules:

```python
# File and directory filtering using configuration-driven exclusion rules
should_process_py = config.should_process_file(Path("src/module.py"))  # True
should_process_cache = config.should_process_file(Path("file.pyc"))    # False
should_process_src = config.should_process_directory(Path("src/"))     # True
should_process_git = config.should_process_directory(Path(".git/"))    # False
```

This example shows handler-specific configuration loading with auto-generation:

```python
# Handler-specific configuration loading with automatic JSON generation
git_config = IndexingConfig.load_for_handler("git-clones")
pdf_config = IndexingConfig.load_for_handler("pdf-knowledge", Path("/custom/knowledge"))
# Automatically generates missing configuration files from centralized defaults
```

### {PROJECT_ROOT}/jesse-framework-mcp/jesse_framework_mcp/knowledge_bases/models/knowledge_context.py

*Last Updated: 2025-07-06T23:07:18Z*

#### Functional Intent & Features

This module provides runtime context data models for the Jesse Framework MCP's Knowledge Bases Hierarchical Indexing System, enabling comprehensive tracking of directory processing, file analysis, change detection, and indexing operation status throughout the hierarchical processing workflow. The module delivers immutable context structures through `FileContext` and `DirectoryContext` classes that support thread-safe operations, comprehensive processing statistics via `ProcessingStats`, and overall operation coordination through `IndexingStatus`. Key semantic entities include `ProcessingStatus` enum for state tracking, `ChangeType` enum for incremental processing, `ChangeInfo` for timestamp-based change detection, and bottom-up hierarchical context assembly without parent-to-child dependencies. The module enables developers to implement robust indexing workflows with accurate progress reporting, error tracking, and performance analysis capabilities essential for large-scale knowledge base operations.

##### Main Components

The module contains five primary dataclass models and two enumeration types. `FileContext` provides immutable file-level processing context with metadata, status tracking, and LLM analysis content storage. `DirectoryContext` delivers hierarchical directory processing context with child file aggregation, subdirectory relationships, and processing statistics calculation. `ChangeInfo` tracks detected changes during incremental indexing operations with timestamp-based change detection. `ProcessingStats` offers mutable statistics tracking for comprehensive performance metrics and error reporting. `IndexingStatus` provides overall operation status coordination and progress tracking. `ProcessingStatus` enum defines processing state transitions, while `ChangeType` enum categorizes change detection scenarios.

###### Architecture & Design

The architecture follows immutable context pattern design using frozen dataclasses for `FileContext`, `DirectoryContext`, and `ChangeInfo` to ensure thread-safe concurrent operations. The design implements clear separation between processing state and configuration through dedicated context structures. Bottom-up hierarchical context assembly enables parent directory processing without requiring child dependencies. Mutable statistics classes `ProcessingStats` and `IndexingStatus` provide real-time updates during processing operations. The design uses string-based enums for serialization compatibility and debugging clarity. Comprehensive tracking architecture supports both incremental and full indexing operations with timestamp-based change detection and processing status transitions.

####### Implementation Approach

The implementation utilizes dataclass field factories for default list initialization and property methods for calculated statistics. Processing duration calculations use datetime arithmetic with safe None handling for incomplete timing information. Completion tracking implements recursive aggregation through child context traversal for accurate progress reporting. Change detection employs timestamp comparison strategies with content change classification for processing optimization. Statistics calculation uses generator expressions for memory efficiency with large directory trees. The approach implements comprehensive error tracking with message preservation and chronological ordering. Serialization support uses dictionary conversion with ISO timestamp formatting for external system integration.

######## External Dependencies & Integration Points

**→ Inbound:** [what this file depends on]
- `dataclasses` (external library) - frozen dataclass implementation for immutable context structures
- `datetime` (external library) - timestamp handling and processing duration calculations
- `pathlib.Path` (external library) - filesystem path operations and validation
- `typing` (external library) - type annotations for Optional, List, Dict, Set, Any
- `enum.Enum` (external library) - string-based enumeration definitions

**← Outbound:** [what depends on this file]
- `knowledge_bases/indexing/hierarchical_indexer.py` - primary consumer of context models for indexing operations
- `knowledge_bases/tools/` - FastMCP tools using IndexingStatus for progress reporting
- `knowledge_bases/change_detection/` - change detection systems using ChangeInfo and ChangeType
- External monitoring systems - consuming ProcessingStats.to_dict() and IndexingStatus.to_dict() outputs

**⚡ System role and ecosystem integration:**
- **System Role**: Core data model foundation for the entire Knowledge Bases Hierarchical Indexing System providing context tracking and statistics
- **Ecosystem Position**: Central component enabling hierarchical processing workflow coordination and progress reporting across the Jesse Framework MCP
- **Integration Pattern**: Used by hierarchical indexer for context management, FastMCP tools for status reporting, and external systems for monitoring through serialization methods

######### Edge Cases & Error Handling

The module handles empty directory scenarios through `DirectoryContext.is_ready_for_summary` preventing indexing of totally empty directories while accepting completed empty directories. Division by zero protection exists in percentage calculations returning 0.0 for empty collections. Incomplete timing information handling returns None for processing duration calculations when start or end times are missing. Error message preservation maintains chronological order through `ProcessingStats.add_error` method. Change detection handles missing timestamp scenarios with Optional datetime fields. Processing status transitions support both successful and failed scenarios through comprehensive enum values. Thread-safe operations rely on immutable context structures preventing concurrent modification issues.

########## Internal Implementation Details

Property methods use conditional expressions and generator comprehensions for efficient calculation of aggregated statistics. Frozen dataclass implementation prevents accidental mutation during concurrent processing operations. Default factory functions ensure proper list initialization without shared mutable defaults. ISO timestamp formatting in serialization methods provides standard compatibility for external system integration. Recursive statistics calculation traverses subdirectory contexts using sum aggregation for memory efficiency. Error tracking uses list append operations maintaining insertion order for debugging analysis. String-based enum inheritance enables both enumeration behavior and serialization compatibility. Optional field handling uses None checks preventing attribute errors during incomplete processing states.

########### Code Usage Examples

This example demonstrates creating file context for processing tracking with timing and error handling. The code shows how to initialize FileContext instances and track processing duration through immutable context updates.

```python
from pathlib import Path
from datetime import datetime
from knowledge_context import FileContext, ProcessingStatus

# Create file context for processing
file_ctx = FileContext(
    file_path=Path("src/main.py"),
    file_size=1024,
    last_modified=datetime.now(),
    processing_status=ProcessingStatus.PROCESSING,
    processing_start_time=datetime.now()
)

# Update with completion
completed_ctx = FileContext(
    file_path=file_ctx.file_path,
    file_size=file_ctx.file_size,
    last_modified=file_ctx.last_modified,
    processing_status=ProcessingStatus.COMPLETED,
    knowledge_content="LLM analysis result",
    processing_start_time=file_ctx.processing_start_time,
    processing_end_time=datetime.now()
)

print(f"Processing took {completed_ctx.processing_duration} seconds")
```

This example shows directory context creation with readiness checking for hierarchical processing. The code demonstrates how to aggregate file contexts and check processing readiness for parent directory operations.

```python
from knowledge_context import DirectoryContext, ProcessingStatus

# Create directory context with file contexts
dir_ctx = DirectoryContext(
    directory_path=Path("src/"),
    file_contexts=[completed_ctx],
    processing_status=ProcessingStatus.PENDING
)

# Check readiness for summary generation
if dir_ctx.is_ready_for_summary:
    print(f"Directory ready: {dir_ctx.completion_percentage}% complete")
    print(f"Total files: {dir_ctx.total_files}, Completed: {dir_ctx.completed_files}")
```

### {PROJECT_ROOT}/jesse-framework-mcp/jesse_framework_mcp/knowledge_bases/models/rebuild_decisions.py

*Last Updated: 2025-07-06T23:07:18Z*

#### Functional Intent & Features

Structured decision models providing immutable data structures for rebuild and deletion operations in the Jesse Framework MCP knowledge base hierarchical indexing system. Provides comprehensive decision outcome tracking through `RebuildDecision` and `DeletionDecision` classes with type-safe `DecisionOutcome` and `DecisionReason` enumerations, enabling centralized decision logic with clear audit trails and comprehensive action planning via `DecisionReport` class. Enables developers to create reliable, auditable decision workflows with rich reasoning capture, performance statistics, and execution coordination for all indexing operations. Key semantic entities include `DecisionOutcome`, `DecisionReason`, `RebuildDecision`, `DeletionDecision`, `DecisionReport`, `dataclasses.dataclass`, `dataclasses.field`, `enum.Enum`, `pathlib.Path`, `datetime.datetime`, and `typing` annotations for comprehensive decision modeling using immutable frozen dataclasses ensuring audit trail integrity and preventing post-creation modification.

##### Main Components

Core enumeration classes `DecisionOutcome` defining five possible outcomes (REBUILD, SKIP, DELETE, CREATE, ERROR) and `DecisionReason` providing comprehensive reasoning categories for all decision scenarios including rebuild reasons, skip reasons, delete reasons, create reasons, and error reasons. Immutable decision data classes `RebuildDecision` capturing rebuild outcomes with path, outcome, reason, reasoning text, timestamp, and metadata, and `DeletionDecision` capturing deletion outcomes with additional safety validation through `is_safe_to_delete` and `backup_recommended` flags. Comprehensive reporting class `DecisionReport` containing decision dictionaries, organized action lists, analysis metadata, and error tracking with methods for decision management, statistics calculation, and reasoning analysis.

###### Architecture & Design

Implements immutable decision architecture using frozen dataclasses ensuring audit trail integrity and preventing modification after creation. Uses type-safe enumeration design with `DecisionOutcome` and `DecisionReason` preventing ambiguous decision interpretation and enabling clear outcome validation. Employs comprehensive action planning through `DecisionReport` with separate decision dictionaries and organized action lists enabling targeted execution and error handling. Implements rich metadata capture with optional metadata dictionaries, timestamp tracking, and performance statistics collection supporting debugging and optimization requirements. Uses property-based decision validation with convenience properties like `should_rebuild`, `should_skip`, and `is_error` simplifying decision logic and conditional processing.

####### Implementation Approach

Uses frozen dataclass pattern with `@dataclass(frozen=True)` ensuring immutability and audit trail integrity while providing automatic initialization and field validation. Implements default factory pattern with `field(default_factory=datetime.now)` and `field(default_factory=dict)` for timestamp generation and metadata initialization. Employs dictionary-based decision storage with `Dict[Path, RebuildDecision]` and `Dict[Path, DeletionDecision]` enabling efficient path-based decision lookup and deduplication. Uses set-based action lists with `Set[Path]` for files_to_rebuild, files_to_delete, directories_to_create, and directories_to_delete ensuring unique operations and preventing duplicate actions. Implements comprehensive statistics calculation through decision counting and categorization with structured dictionary returns for monitoring integration.

######## External Dependencies & Integration Points

**→ Inbound:**
- `dataclasses` (external library) - Immutable decision object creation with automatic initialization and field validation
- `datetime` (external library) - Timestamp tracking for decision timing and audit trail construction
- `enum` (external library) - Type-safe decision outcome and reasoning enumeration with clear value definitions
- `pathlib.Path` (external library) - Cross-platform path operations and file system entity identification
- `typing` (external library) - Type annotations for decision object integrity and IDE support

**← Outbound:**
- `jesse_framework_mcp.knowledge_bases.indexing.rebuild_decision_engine:RebuildDecisionEngine` - Consumes decision models for centralized decision logic implementation
- `jesse_framework_mcp.knowledge_bases.indexing.plan_generator:PlanGenerator` - Uses decision reports for execution plan generation and task creation
- `jesse_framework_mcp.knowledge_bases.indexing.hierarchical_indexer:HierarchicalIndexer` - Receives decision reports for coordinated processing execution
- Monitoring and logging systems - Consume decision statistics and reasoning summaries for analysis and debugging
- Audit trail systems - Use immutable decision objects for compliance and troubleshooting requirements

**⚡ System role and ecosystem integration:**
- **System Role**: Foundational data model layer providing structured decision representation for all rebuild and deletion operations within the Jesse Framework MCP knowledge base indexing system
- **Ecosystem Position**: Core infrastructure component enabling centralized decision logic by providing immutable, type-safe decision objects with comprehensive audit trails and action planning capabilities
- **Integration Pattern**: Used by decision engines and execution planners as primary data structures for decision communication, with decision reports serving as comprehensive action plans for coordinated processing workflows

######### Edge Cases & Error Handling

Handles missing decisions through `get_decision_for_path()` returning `None` when no decision exists for specified path, enabling graceful handling of incomplete decision scenarios. Manages decision errors through dedicated `DecisionOutcome.ERROR` and error-specific `DecisionReason` values like `FILESYSTEM_ERROR`, `ACCESS_DENIED`, and `DECISION_ERROR` with comprehensive error tracking in `decision_errors` list. Provides safety validation for deletion decisions through `is_safe_to_delete` boolean flag and `backup_recommended` flag preventing accidental data loss and supporting rollback scenarios. Implements comprehensive error detection through `has_errors()` method checking both decision_errors list and individual decision outcomes for error conditions. Uses immutable design preventing accidental modification of decision objects after creation, ensuring audit trail integrity even in error scenarios.

########## Internal Implementation Details

Uses frozen dataclass implementation with automatic `__init__`, `__repr__`, and `__eq__` generation while preventing attribute modification through `frozen=True` parameter. Implements default factory pattern for mutable default values using `field(default_factory=dict)` and `field(default_factory=set)` preventing shared mutable defaults across instances. Maintains decision consistency through automatic action list updates in `add_rebuild_decision()` and `add_deletion_decision()` methods ensuring decision records match execution lists. Uses path-based dictionary keys enabling efficient O(1) decision lookup and preventing duplicate decisions for same paths. Implements comprehensive statistics calculation through list comprehensions and filtering operations providing real-time decision analysis and monitoring capabilities.

########### Code Usage Examples

Essential decision creation and management pattern for rebuild operations. This pattern demonstrates how to create immutable decision objects and integrate them with comprehensive reporting systems for coordinated processing workflows.

```python
# Create immutable rebuild decision with comprehensive metadata and reasoning
rebuild_decision = RebuildDecision(
    path=Path("src/components/button.py"),
    outcome=DecisionOutcome.REBUILD,
    reason=DecisionReason.CACHE_STALE,
    reasoning_text="Source file is newer than analysis cache",
    metadata={"file_size": 1024, "cache_age": 3600}
)

# Add decision to report for comprehensive action planning
report = DecisionReport()
report.add_rebuild_decision(rebuild_decision)

# Access decision properties for conditional processing
if rebuild_decision.should_rebuild:
    print(f"Rebuilding {rebuild_decision.path}")
```

Comprehensive decision reporting and analysis for monitoring and debugging. This approach enables detailed decision analysis and execution coordination through structured reporting and statistics generation.

```python
# Create deletion decision with safety validation and backup recommendation
deletion_decision = DeletionDecision(
    path=Path("cache/orphaned_file.md"),
    outcome=DecisionOutcome.DELETE,
    reason=DecisionReason.ORPHANED_ANALYSIS_CACHE,
    reasoning_text="Analysis cache has no corresponding source file",
    is_safe_to_delete=True,
    backup_recommended=False
)

# Generate comprehensive statistics and reasoning analysis
stats = report.get_summary_statistics()
reasoning_summary = report.get_reasoning_summary()
has_errors = report.has_errors()

# Access organized action lists for execution coordination
files_to_rebuild = report.files_to_rebuild
files_to_delete = report.files_to_delete
```

---
*Generated: 2025-07-06T23:07:18Z*
*Source Directory: {PROJECT_ROOT}/jesse-framework-mcp/jesse_framework_mcp/knowledge_bases/models*
*Total Files: 5*
*Total Subdirectories: 0*

# End of models_kb.md